{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtTP1T1tgiOBP4FE5XuQtY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimnathw/mathematics-for-machine-learning/blob/main/linear_algebra_for_ML_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Algebra for Machine Learning\n",
        "\n",
        "### Linear Algebra I\n",
        "**Week 1: Vectors and Operations**\n",
        "- Introduction to vectors: magnitude, direction, interpretation\n",
        "- Addition of two vectors as linear combinations\n",
        "\n",
        "**Week 2: Dot and Cross Products**\n",
        "- Geometric interpretation of dot product\n",
        "- Geometric interpretation of cross product\n",
        "- Calculating area of triangles, parallelograms, and parallelepipeds\n",
        "\n",
        "**Week 3: Vector Decomposition and Planes**\n",
        "- Vector decomposition with respect to another vector\n",
        "- Formula for decomposition with respect to another vector\n",
        "- Equation of a plane with two given vectors\n",
        "\n",
        "**Week 4: Distance Calculation**\n",
        "- Equation of a line\n",
        "- Equation of a plane\n",
        "- Calculating distance between a point and a line\n",
        "- Calculating distance between a point and a plane\n",
        "\n",
        "**Week 5: Linear Independence and Span**\n",
        "- Understanding linear independence and span\n",
        "- Gaussian elimination and Gauss-Jordan elimination\n",
        "\n",
        "**Week 6: Matrix Interpretation**\n",
        "- Interpreting matrices as linear transformations\n",
        "\n",
        "**Week 7: Subspaces**\n",
        "- Rank of a Matrix\n",
        "- Subspaces, column space, row space, and null space of matrices\n",
        "\n",
        "**Week 8: Fundamental Theorem of Linear Algebra**\n",
        "- Orthonormal vectors\n",
        "- Rank-Nullity Theorem\n",
        "- Fundamental Theorem of Linear Algebra\n",
        "\n",
        "**Week 9: Types of Matrices**\n",
        "- Identity Matrix\n",
        "- Rotation Matrix\n",
        "- Dilation Matrix\n",
        "- Shear Matrix\n",
        "\n",
        "**Week 10: Determinants and Invertibility**\n",
        "- Interpreting determinants\n",
        "- Understanding the invertibility of matrices\n",
        "- Rank and non-singular matrices\n",
        "\n",
        "**Week 11: Matrix Composition**\n",
        "- Interpreting matrix matrix multiplicaion\n",
        "- Elementary Row Matrices\n",
        "- Properties of Matrix Multiplication\n",
        "- Orthogonal Matrices\n",
        "\n",
        "**Week 12: Matrix Decompositions**\n",
        "- LU decomposition\n",
        "\n",
        "**Week 13: QR decomposition**\n",
        "\n",
        "**Week 14: Eigen decomposition**\n",
        "\n",
        "**Week 15: Symmetric Matrices and Positive Definite Matrices**\n",
        "- Covariance Matrices\n",
        "- Gradient Vectors and Hessian Matrices\n",
        "- Critical Point Analysis\n",
        "\n",
        "**Week 16: Singular Value Decomposition (SVD)**\n",
        "- Interpratation of SVD as a change of basis\n",
        "\n",
        "**Week 17: Principal Component Analysis (PCA)**\n",
        "- PCA with Eigen Decomposition\n",
        "- PCA with SVD\n",
        "\n",
        "----\n",
        "\n",
        "### Linear Algebra II\n",
        "\n",
        "**Week 1: Solve Linear Regression**\n",
        "- QR decomposition for direct estimation of Linear Regression models\n",
        "\n",
        "**Week 2: Gradient Descent Algorithm**\n",
        "- Jacaboian, Gradient, Hessian Matrices\n",
        "- Modular Approach to Machine Learning\n",
        "- Gradient Descent Algorithm\n",
        "- Regularization\n",
        "\n",
        "**Week 3: Neural Networks**\n",
        "- Back-propogation Algorithm in Neural Networks\n",
        "\n",
        "**Week 4: Complex Vectors and Complex Matrices**\n",
        "- Hermitian Matrices\n",
        "\n",
        "**Week 5: Solve Differential Equations**\n",
        "\n",
        "**Week 6: Graph Theory and Network Ananlysis**\n",
        "\n",
        "**Week 7: Decision Trees**\n",
        "\n",
        "**Week 8: Numerical Linear Algebra**\n",
        "\n"
      ],
      "metadata": {
        "id": "n3PP00NB0z_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression\n",
        "\n",
        "1. **Objective Function:**\n",
        "   - In linear regression, the goal is to minimize the sum of squared errors between the actual target variable $y$ and the predicted values from the linear model $X \\beta$.\n",
        "   - This can be expressed as the optimization problem $$\\min ||y - X \\beta||^2$$.\n",
        "\n",
        "2. **Expressing in Matrix Form:**\n",
        "   - The squared error function can be expanded and expressed in matrix form as $\\min ||y - X \\beta||^2 = \\min ||y - X \\beta||^2 = \\min (y - X \\beta)^T (y - X \\beta)$.\n",
        "   - $ (y - X\\beta)^T (y - X\\beta) $ expands to $ y^T y - 2 \\beta^T X^T y + \\beta^T X^T X \\beta $.\n",
        "\n",
        "\n",
        "3. **Deriving the Normal Equation:**\n",
        "   - To minimize the objective function, we take the derivative with respect to $\\beta$ and set it to zero, yielding\n",
        "   $$- 2* X^T y +2 *X^TX \\beta = 0$$.\n",
        "   $$=> \\beta = (X^TX)^{-1} X^T y$$\n",
        "\n",
        "4. **QR Decomposition:**\n",
        "   - QR decomposition decomposes the feature matrix $X$ into an orthogonal matrix $Q$ and an upper triangular matrix $R$. This yields the equation $X = QR$.\n",
        "\n",
        "5. **Transforming the Equation:**\n",
        "\n",
        "  - Substitute the QR decomposition of $X$ into the equation:\n",
        "\n",
        "   $$\\beta = (X^TX)^{-1}X^Ty$$\n",
        "\n",
        "  - Since $X = QR$, the equation becomes:\n",
        "\n",
        "   $$\\beta = (R^TQ^TQR)^{-1}R^TQ^Ty$$\n",
        "\n",
        "  - Given that $Q$ is orthogonal, $Q^TQ$ is the identity matrix, so we get:\n",
        "\n",
        "   $$\\beta = (R^TR)^{-1}R^TQ^Ty$$\n",
        "\n",
        "   $$\\beta = R^{-1}(R^T)^{-1}R^TQ^Ty$$\n",
        "\n",
        "   - Due to the properties of inverse matrices, $(R^T)^{-1}R^T$ equals the identity matrix, simplifying the equation to $$\\beta = R^{-1}Q^T y$$.\n",
        "\n",
        "6. **Parameter Interpretation:**\n",
        "   - The resulting parameter vector $\\beta$ represents the coefficients of the features in the linear regression model.\n",
        "   - Each element in $\\beta$ corresponds to the impact of the respective feature on the target variable, providing insights into the relationship between the features and the target variable."
      ],
      "metadata": {
        "id": "eAjXV1Jiq9dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Simulating data for 100 patients\n",
        "num_patients = 100\n",
        "\n",
        "# Creating synthetic data for features and target variable\n",
        "molecular_weight = np.random.uniform(100, 500, num_patients)\n",
        "solubility = np.random.uniform(0.1, 0.9, num_patients)\n",
        "clinical_data = np.random.randint(1, 4, num_patients)  # 1, 2, 3 representing different clinical trial phases\n",
        "patient_age = np.random.randint(18, 80, num_patients)\n",
        "bioactivity = 0.5 * molecular_weight + 0.8 * solubility + 0.1 * clinical_data + np.random.normal(0, 10, num_patients)\n",
        "\n",
        "# Creating the 2D array\n",
        "data = np.column_stack((molecular_weight, solubility, clinical_data, patient_age, bioactivity))\n",
        "\n",
        "# Column names for the features\n",
        "column_names = ['Intercept', 'Molecular Weight', 'Solubility', 'Clinical Data', 'Patient Age']\n",
        "\n",
        "# Printing the array\n",
        "#print(data)\n",
        "\n",
        "\n",
        "# Extracting features and the target variable\n",
        "X = data[:, :-1]  # Features\n",
        "y = data[:, -1]  # Target variable\n",
        "\n",
        "# Adding an intercept term by appending a column of ones to the feature matrix\n",
        "intercept = np.ones((X.shape[0], 1))\n",
        "X_with_intercept = np.hstack((intercept, X))\n",
        "\n",
        "# Performing QR decomposition\n",
        "Q, R = np.linalg.qr(X_with_intercept)\n",
        "\n",
        "# Solving for the parameter (b values) vector using the formula: b = (Q^T * y) / R\n",
        "b = np.linalg.inv(R).dot(Q.T).dot(y)\n",
        "\n",
        "# Printing the parameter vector\n",
        "print(\"Parameter vector (b values):\")\n",
        "print(b)\n",
        "\n",
        "# Printing the column names and corresponding beta values\n",
        "print(\"Corresponding Beta Values:\")\n",
        "for i in range(len(column_names)):\n",
        "    print(f\"{column_names[i]}: {b[i]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7x6QfF5q9JK",
        "outputId": "ae551af0-04a8-4c94-d0d3-177e546f3b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter vector (b values):\n",
            "[ 0.86496178  0.50559983  0.12998637 -0.66860361 -0.0271114 ]\n",
            "Corresponding Beta Values:\n",
            "Intercept: 0.8649617793285911\n",
            "Molecular Weight: 0.5055998300627698\n",
            "Solubility: 0.1299863667640042\n",
            "Clinical Data: -0.6686036060237033\n",
            "Patient Age: -0.027111399567728012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jacobian, Gradient and Hessian Matrices in Multivariate Calculus\n",
        "\n",
        "\n",
        "- Multivariate calculus extends the principles of calculus to functions of multiple variables.\n",
        "- The Jacobian and Hessian matrices are essential tools in multivariate calculus, particularly in optimization, where they help analyze local behavior.\n",
        "\n",
        "**1.1 Jacobian Matrix**\n",
        "- The Jacobian matrix represents the derivative of a vector-valued function.\n",
        "- Let $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ be a **vector-valued** function.\n",
        "- The Jacobian matrix $J_f$ has dimensions $m \\times n$ and is defined as:\n",
        " $$J_f = \\begin{bmatrix}\n",
        "  \\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\cdots & \\frac{\\partial f_1}{\\partial x_n}\\\\\n",
        "  \\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\cdots & \\frac{\\partial f_2}{\\partial x_n}\\\\\n",
        "  \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "  \\frac{\\partial f_m}{\\partial x_1} & \\frac{\\partial f_m}{\\partial x_2} & \\cdots & \\frac{\\partial f_m}{\\partial x_n}\\\\\n",
        "  \\end{bmatrix}$$\n",
        "- Each entry of the Jacobian represents the partial derivative of one component of $f$ with respect to one of the input variables.\n",
        "\n",
        "**1.2 Gradient**\n",
        "\n",
        "For a scalar-valued function, the matrix of first partial derivatives is simply a row vector or a column vector, depending on the convention used. If you have a scalar function $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$, the matrix of first partial derivatives is usually represented as either a row vector or a column vector, depending on whether you want to treat it as a row or column.\n",
        "\n",
        "Let's take a function $f(x_1, x_2, \\ldots, x_n)$ with \\(n\\) variables. The matrix of first partial derivatives is given by:\n",
        "\n",
        "$$\n",
        "\\nabla f = \\left[\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n}\\right]\n",
        "$$\n",
        "\n",
        "or\n",
        "\n",
        "$$\n",
        "\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n} \\end{bmatrix}\n",
        "$$\n",
        "This matrix is also referred to as the gradient of the scalar function.\n",
        "\n",
        "\n",
        "**1.3 Hessian Matrix**\n",
        "- The Hessian matrix is used to analyze the second-order behavior of a scalar-valued function.\n",
        "- Let $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ be a **scalar-valued** function.\n",
        "- The Hessian matrix $\\mathcal{H}_f$ has dimensions $n \\times n$ and is defined as:\n",
        "$$\\mathcal{H}_f = \\begin{bmatrix}\n",
        "  \\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n}\\\\\n",
        "  \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n}\\\\\n",
        "  \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "  \\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}\\\\\n",
        "  \\end{bmatrix}$$\n",
        "- The diagonal entries represent second partial derivatives with respect to individual variables, while off-diagonal entries represent mixed partial derivatives.\n",
        "\n",
        "**1.4 Significance of Jacobian and Hessian Matrices**\n",
        "-     The Jacobian matrix and gradient play a vital role in optimization tasks, aiding in the determination of the direction and rate of the fastest increase of a scalar field.\n",
        "- The Hessian matrix is instrumental in understanding the curvature of the function, enabling the identification of critical points, such as minima, maxima, and saddle points, within the scalar field.\n",
        "\n",
        "**1.5 Examples**\n",
        "Consider the function $$f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2$$ defined as:\n",
        "\n",
        "$$f(x, y) = \\begin{bmatrix}\n",
        "    3x^2 + 2y \\\\\n",
        "    x^3 - y^2\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "**1.5.1 Calculation of Jacobian Matrix (J_f):**\n",
        "\n",
        "To find the Jacobian matrix, we need to compute the partial derivatives of each component of the vector function with respect to each input variable.\n",
        "\n",
        "So, we have:\n",
        "\n",
        "$$\\frac{\\partial f_1}{\\partial x} = 6x, \\quad \\frac{\\partial f_1}{\\partial y} = 2$$\n",
        "$$\\frac{\\partial f_2}{\\partial x} = 3x^2, \\quad \\frac{\\partial f_2}{\\partial y} = -2y$$\n",
        "\n",
        "Hence, the Jacobian matrix, $J_f$, is:\n",
        "\n",
        "$$J_f = \\begin{bmatrix}\n",
        "    6x & 2 \\\\\n",
        "    3x^2 & -2y\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "**1.5.2 Calculation of Gradient and Hessian Matrix ($\\mathcal{H}_f$):**\n",
        "\n",
        "Consider the following scalar function:\n",
        "$$f(x, y) = x^2 + 3xy + 2y^2$$\n",
        "\n",
        "**Calculation of Gradient:**\n",
        "\n",
        "To find the gradient of the function $f(x, y) = x^2 + 3xy + 2y^2$, we compute the partial derivatives with respect to each input variable:\n",
        "\n",
        "$$\\nabla f = \\begin{bmatrix}\n",
        "    \\frac{\\partial f}{\\partial x} \\\\\n",
        "    \\frac{\\partial f}{\\partial y}\n",
        "\\end{bmatrix}\n",
        "= \\begin{bmatrix}\n",
        "    2x + 3y \\\\\n",
        "    3x + 4y\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "**Calculation of Hessian Matrix:**\n",
        "\n",
        "To find the Hessian matrix, we need to compute the second-order mixed partial derivatives of the function $f(x, y) = x^2 + 3xy + 2y^2$.\n",
        "\n",
        "$$\\frac{\\partial^2 f}{\\partial x^2} = 2, \\quad \\frac{\\partial^2 f}{\\partial y^2} = 4, \\quad \\frac{\\partial^2 f}{\\partial x \\partial y} = 3, \\quad\n",
        "\\frac{\\partial^2 f}{\\partial y \\partial x} = 3$$\n",
        "\n",
        "Hence, the Hessian matrix, \\(H_f\\), is:\n",
        "\n",
        "$$H_f = \\begin{bmatrix}\n",
        "    2 & 3 \\\\\n",
        "    3 & 4\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "In this example, the gradient represents the vector of first-order derivatives of the scalar function, while the Hessian matrix represents the matrix of second-order mixed partial derivatives, providing information about the curvature and behavior of the function at a particular point. These concepts are crucial in optimization, machine learning, and various fields of mathematics and science."
      ],
      "metadata": {
        "id": "5CH1jWa8_5D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Properties of Jacobian, Gradient and Hessian Matrices**\n",
        "\n",
        "**Objective:** In this lecture, we will explore the properties of Jacobian and Hessian matrices, as well as their applications in various fields.\n",
        "\n",
        "**1. Properties of Jacobian Matrix**\n",
        "1. **Properties of linearity and the chain rule:** The Jacobian matrix, when applied to vector-valued functions, exhibits properties of linearity and obeys the chain rule. This property allows it to capture the local behavior of vector-valued functions, providing insights into how small changes in the input variables affect the outputs. In essence, linearity enables the Jacobian matrix to approximate a complex, nonlinear function around a specific point using a linear transformation. This approximation is crucial for understanding the behavior of functions in the vicinity of a given point.\n",
        "\n",
        "2. **Analyzing the rate of change of vector-valued functions:** The Jacobian matrix serves as a fundamental tool for analyzing the rate of change of vector-valued functions. By capturing the derivatives of each component of the function with respect to each input variable, the Jacobian matrix offers valuable information about how small changes in the input variables impact the function's output. This understanding is vital in various mathematical fields, including physics, engineering, and economics, where the analysis of complex systems often relies on comprehending the rate of change of multiple variables simultaneously.\n",
        "\n",
        "3. **Relation to the gradient and insights into directional derivatives:** The Jacobian matrix is directly related to the gradient of a scalar field. It provides insights into the directional derivative, helping to understand how a function changes in a particular direction. By using the components of the Jacobian matrix, it is possible to determine the direction of the fastest increase of the vector-valued function. This knowledge is crucial for studying the local behavior of vector fields, identifying critical points, and analyzing the behavior of functions in various real-world applications.\n",
        "\n",
        "\n",
        "**2. Properties of Gradient**\n",
        "- The gradient of a scalar field points in the direction of the steepest ascent. It is perpendicular to the level sets of the function, indicating the direction of the fastest increase of the scalar field. Furthermore, the gradient is zero at local minima and maxima.\n",
        "\n",
        "**3. Properties of Hessian Matrix**\n",
        "- The Hessian matrix is symmetric and real.\n",
        "- It possesses properties of symmetry and definiteness, offering valuable information about the curvature of the scalar function. Moreover, the Hessian matrix is directly linked to the second-order Taylor expansion, aiding in the characterization of critical points and the identification of inflection points.\n",
        "\n",
        "**Applications:**\n",
        "- The Jacobian matrix finds extensive use in the study of transformations, differential equations, and optimization problems, especially in the realms of robotics, computer graphics, and physics.\n",
        "- The Hessian matrix plays a vital role in optimization algorithms, image processing, and machine learning, contributing to the identification of convex and non-convex regions and assisting in the determination of convergence rates in iterative methods.\n",
        "- In neural networks, they play a role in backpropagation and weight update rules."
      ],
      "metadata": {
        "id": "2wEODVvIBgzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy as sp\n",
        "\n",
        "# Define the symbols\n",
        "x, y = sp.symbols('x y')\n",
        "\n",
        "# Define the vector-valued function f(x, y)\n",
        "f1 = 3*x**2 + 2*y\n",
        "f2 = x**3 - y**2\n",
        "f = sp.Matrix([f1, f2])\n",
        "\n",
        "# Calculate the Jacobian matrix J_f\n",
        "J_f = f.jacobian([x, y])\n",
        "\n",
        "# Print the Jacobian matrix\n",
        "print(\"Jacobian Matrix J_f:\")\n",
        "sp.pprint(J_f)\n",
        "\n",
        "# Define the scalar function f(x, y)\n",
        "f_scalar = x**2 + 3*x*y + 2*y**2\n",
        "\n",
        "# Calculate the gradient of the scalar function\n",
        "gradient = sp.Matrix([sp.diff(f_scalar, x), sp.diff(f_scalar, y)])\n",
        "\n",
        "# Print the gradient\n",
        "print(\"\\nGradient of the Scalar Function:\")\n",
        "sp.pprint(gradient)\n",
        "\n",
        "# Calculate the Hessian matrix of the scalar function\n",
        "hessian = sp.hessian(f_scalar, (x, y))\n",
        "\n",
        "# Print the Hessian matrix\n",
        "print(\"\\nHessian Matrix H_f:\")\n",
        "sp.pprint(hessian)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTg93jN1NNVl",
        "outputId": "a773b261-26e0-4af0-92b2-e87f9d2646e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian Matrix J_f:\n",
            "⎡6⋅x    2  ⎤\n",
            "⎢          ⎥\n",
            "⎢   2      ⎥\n",
            "⎣3⋅x   -2⋅y⎦\n",
            "\n",
            "Gradient of the Scalar Function:\n",
            "⎡2⋅x + 3⋅y⎤\n",
            "⎢         ⎥\n",
            "⎣3⋅x + 4⋅y⎦\n",
            "\n",
            "Hessian Matrix H_f:\n",
            "⎡2  3⎤\n",
            "⎢    ⎥\n",
            "⎣3  4⎦\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modular Approach to Machine Learning and Application to Linear Regression\n",
        "**Modular approach:**\n",
        "\n",
        "    1. Choose a model that describes the relationships between variables of interest.\n",
        "    2. Define a loss function that quantifies the extent to which the fit to the data is poor.\n",
        "    3. Choose a regularizer that expresses how much we prefer different candidate explanations.\n",
        "    4. Fit the model, using optimization algorithms.\n",
        "\n",
        "**Application to Linear Regression**\n",
        "\n",
        "1. **Model Selection**: We begin by choosing a model that effectively describes the relationships between the variables of interest. For linear regression, this model is represented as:\n",
        "   \n",
        "   $y = X \\cdot w + b_0$,\n",
        "   \n",
        "   where:\n",
        "   - $y$ is the vector of predictions,\n",
        "   - $X$ is the input matrix,\n",
        "   - $w$ is the weight vector, and\n",
        "   - $b_0$ is the scalar bias term.\n",
        "\n",
        "  For a single data point $i$, this preditcion function is given by:\n",
        "   \n",
        "   $$y^{(i)}= (x^{(i)})^{T} \\cdot w + b_0$$\n",
        "\n",
        "   - $y_i$ is the scalar prediction for data point $i$,\n",
        "   - $x_i^{T}$ is the row vector of feature observations for data point $i$,\n",
        "   - $w$ is the weight vector, and\n",
        "   - $b_0$ is the scalar bias term.\n",
        "  \n",
        "Example augmented matrix with five observations:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "x^{1}_{1} & x^{1}_{2} & x^{1}_{3} & 1 & y^1 \\\\\n",
        "x^{2}_{1} & x^{2}_{2} & x^{2}_{3} & 1 & y^2 \\\\\n",
        "x^{3}_{1} & x^{3}_{2} & x^{3}_{3} & 1 & y^3 \\\\\n",
        "x^{4}_{1} & x^{4}_{2} & x^{4}_{3} & 1 & y^4 \\\\\n",
        "x^{5}_{1} & x^{5}_{2} & x^{5}_{3} & 1 & y^5 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $x^{1}_{1}, x^{1}_{2}, x^{1}_{3}$ represent the features for the first observation,\n",
        "- $x^{2}_{1}, x^{2}_{2}, x^{2}_{3}$ represent the features for the second observation,\n",
        "- $x^{3}_{1}, x^{3}_{2}, x^{3}_{3}$ represent the features for the third observation,\n",
        "- $x^{4}_{1}, x^{4}_{2}, x^{4}_{3}$ represent the features for the fourth observation,\n",
        "- $x^{5}_{1}, x^{5}_{2}, x^{5}_{3}$ represent the features for the fifth observation,\n",
        "- $y^1, y^2, y^3, y^4, y^5$ are the corresponding target values for each observation.\n",
        "\n",
        "\n",
        "2. **Loss Function Definition**:\n",
        "  A loss function, also known as an error function, is a function that maps an event or values of one or more variables onto a real number that represents some \"cost\" associated with the event. In the context of training a machine learning model, the loss function is used to measure the inconsistency between the predicted value (output by the model) and the actual target value. The goal during training is to minimize this loss function.\n",
        "\n",
        "  We use the squared error as our loss function to quantify the extent of the discrepancy between predicted and actual values. For a single data point $i$, this loss function is given by:\n",
        "   \n",
        "   $L(y^{(i)}, t^{(i)}) = \\frac{1}{2}(y^{(i)} - t^{(i)})^2$,\n",
        "   \n",
        "   where $y^{(i)}$ is the predicted value and $t$ is the actual target value for the observation $i$.\n",
        "  - $(y^{(i)} - t^{(i)})$ is the residual, and we want to make this small in magnitude\n",
        "  - The 1/2 factor is just to make the calculations convenient.\n",
        "\n",
        "\n",
        "3. **Cost Function Defintion**:\n",
        "  A cost function is closely related to the loss function, but it typically refers to the average loss over the entire training dataset. It incorporates the sum of the loss functions over all the training samples. In this way, the cost function represents the \"cost\" that the model incurs in terms of prediction errors over the entire training dataset. The goal during training is to minimize the cost function, which in turn leads to better generalization on unseen data.\n",
        "\n",
        "  \n",
        "$$J(w, b_0) = \\frac{1}{2N} \\sum_{i=1}^{N} (y^{(i)} - t^{(i)})^2 = \\frac{1}{2N} \\sum_{i=1}^{N} (w \\cdot x^{(i)} + b_0 - t^{(i)})^2$$\n",
        "\n",
        "- $J(w, b_0)$ represents the cost function, where $w$ and $b$ are the parameters of the linear regression model.\n",
        "- $N$ is the number of training examples.\n",
        "- $y^{(i)}$ represents the predicted output of the model for the $i$th training example.\n",
        "- $t^{(i)}$ represents the actual target output for the $i$th training example.\n",
        "- $x^{(i)}$ represents the input features for the $i$th training example.\n",
        "\n",
        " The goal of using this cost function in the context of optimization algorithms such as gradient descent is to minimize the difference between the predicted outputs and the actual targets for all training examples.\n",
        "\n",
        "By minimizing the cost function $J(w, b_0)$, we can find the optimal values for the parameters $w$ and $b_0$ that best fit the training data. This helps in creating a linear model that can accurately predict the target values for new, unseen data.\n",
        "\n",
        "4. **Minimize Loss Fucntion and Cost Function**\n",
        "To minimize the cost function we have to take the partial derivatives cost function to zero. First we will take the partial derivatives of the prediction \\(y\\) with respect to the parameters \\(w_j\\) and \\(b)\\).\n",
        "\n",
        "Partial derivative with respect to \\(w_j\\):\n",
        "$$ \\frac{\\partial y}{\\partial w_j} = \\frac{\\partial}{\\partial w_j} \\left( \\sum_{j'} w_{j'}x_{j'} + b_0 \\right) = x_j $$\n",
        "\n",
        "Partial derivative with respect to \\(b_0\\):\n",
        "$$ \\frac{\\partial y}{\\partial b_0} = \\frac{\\partial}{\\partial b_0} \\left( \\sum_{j'} w_{j'}x_{j'} + b_0 \\right) = 1 $$\n",
        "\n",
        "Now, we will use the chain rule to compute the derivative of composite functions. The chain rule is applied to find the derivatives of the loss function \\(L\\) and the cost function \\(J\\) with respect to the parameters \\(w_j\\) and \\(b\\).\n",
        "\n",
        "Derivative of the loss function for a data point $i$ with respect to \\(w_j\\):\n",
        "$$\\frac{\\partial L}{\\partial w_j} = \\frac{dL}{dy} \\frac{\\partial y}{\\partial w_j} = \\frac{d}{dy} \\left[ \\frac{1}{2} (y^{(i)} - t^{(i)})^2 \\right] \\cdot x_j = (y^{(i)} - t^{(i)}) \\cdot x_j $$\n",
        "\n",
        "Derivative of the loss function for a data point $i$ with respect to \\(b_0\\):\n",
        "$$\\frac{\\partial L}{\\partial b_0} = \\frac{dL}{dy} \\frac{\\partial y}{\\partial b_0} = \\frac{d}{dy} \\left[ \\frac{1}{2} (y^{(i)} - t^{(i)})^2 \\right] \\cdot 1 == y^{(i)} - t^{(i)} $$\n",
        "\n",
        "These derivatives are then averaged over the data points to obtain the derivatives of the cost function \\(J\\) with respect to \\(w_j\\) and \\(b\\), which are given by:\n",
        "\n",
        "Derivative of the cost function with respect to \\(w_j\\):\n",
        "$$\\frac{\\partial J}{\\partial w_j} = \\frac{1}{N} \\sum_{i=1}^{N} (y^{(i)} - t^{(i)}) \\cdot x_j^{(i)} $$\n",
        "\n",
        "Derivative of the cost function with respect to \\(b_0\\):\n",
        "$$\\frac{\\partial J}{\\partial b_0} = \\frac{1}{N} \\sum_{i=1}^{N} (y^{(i)} - t^{(i)}) $$\n",
        "\n",
        "**We can absorb $b_0$ to the $w$ weight vector by adding a column of $1$s as an additional $x_j$ to the matrix $X$.**\n",
        "\n",
        "\n",
        "5. **Apply Gradient Descent Algorithm**\n",
        "\n",
        "The gradient descent algorithm moves in the direction of the steepest decrease of the cost function. The goal is to find the optimal weights that minimize the cost function, thus achieving the best fit of the linear regression model to the data.\n",
        "In the context of the gradient descent algorithm for minimizing the cost function \\(J\\) in linear regression, the key idea is to iteratively update the weights (\\(w\\)) in the direction of the steepest descent. The algorithm is as follows:\n",
        "\n",
        "  a. Initialize the weights to a reasonable value, such as zeros.\n",
        "\n",
        "  b. Calculate the derivatives of the cost function with respect to the weights (\\(w\\)) using the formula:\n",
        "    $$\\frac{\\partial J}{\\partial w_j} = \\frac{1}{N} \\sum_{i=1}^{N} (y^{(i)} - t^{(i)}) \\cdot x_j^{(i)} $$\n",
        "\n",
        "  c. Update the weights using the formula:\n",
        "  $$ w_j = w_j - \\alpha \\frac{\\partial J}{\\partial w_j} $$\n",
        "\n",
        "  $$ w_j = w_j - \\alpha \\frac{1}{N} \\sum_{i=1}^{N} (y^{(i)} - t^{(i)}) x^{(i)} $$\n",
        "\n",
        "  where $\\alpha$ is the learning rate, which controls the size of the steps taken during each iteration. Larger values of $\\alpha$ lead to faster changes in the weights.\n",
        "\n",
        "  d. Repeat steps b and c until a certain stopping criterion is met.\n",
        "\n",
        "6. **Vectorization for Performance**:\n",
        "\n",
        "Vectorization is a technique commonly used in numerical computing to speed up the execution of mathematical operations. It involves rewriting the code to operate on entire arrays or matrices all at once rather than processing elements one by one. Vectorized operations can leverage optimized libraries, such as NumPy in Python, which are implemented in lower-level languages like C or Fortran. These libraries can make use of hardware acceleration, such as utilizing multiple cores and utilizing GPU for matrix operations, leading to significant speedups.By avoiding the overhead associated with interpreting and executing Python loops, vectorized operations can significantly reduce the computational overhead and improve overall performance.\n",
        "In the context of the cost function, we can write using vectorization as:\n",
        "\n",
        "Given the equation:\n",
        "\n",
        "$$y = X \\cdot w + b_0$$\n",
        "\n",
        "where:\n",
        "- $y$ is the vector of predicted values,\n",
        "- \\(X\\) is the dataset matrix,\n",
        "- \\(w\\) is a vector of parameters,\n",
        "- \\(b_0\\) is a scalar constant.\n",
        "\n",
        "The cost function \\(J\\) is defined as:\n",
        "\n",
        "$$J = \\frac{1}{2N} ||y - t||^2$$\n",
        "\n",
        "where:\n",
        "- \\(N\\) is the number of samples in the dataset,\n",
        "- \\(y\\) is the vector of predicted values computed using \\(X\\), \\(w\\), and \\(b_0\\),\n",
        "- \\(t\\) is the vector of target values.\n",
        "\n",
        "**In vectorized form, the gradient descent algortihm can be expressed as follows:**\n",
        "\n",
        "a. Initialize the vector of weights to a reasonable value, such as zeros:\n",
        "$$w = \\mathbf{0}$$\n",
        "\n",
        "b. Compute the predictions vector $y$ for the entire dataset using matrix operations:\n",
        "   $$y = X \\cdot w$$\n",
        "\n",
        "c. Compute the derivative of the cost function with respect to vector $w$ in matrix form:\n",
        "   $$\\nabla_J = \\frac{1}{N} X^T (y - t)$$\n",
        "\n",
        "d. Update the weights using the formula:\n",
        "  $$w = w - \\alpha \\nabla_J$$\n",
        "\n",
        "  $$w = w - \\alpha \\frac{1}{N} X^T (y - t)$$\n",
        "\n",
        "e. Repeat steps c and d until certain stopping criterion is met.\n",
        "\n",
        "In this representation:\n",
        "- \\(X\\) is the matrix representing the input features, where each row corresponds to a training example, and each column corresponds to a feature.\n",
        "- \\(w\\) is the weight vector.\n",
        "- \\(y\\) is the vector of predicted values.\n",
        "- \\(t\\) is the vector of target values.\n",
        "- \\($\\alpha$\\) is the learning rate.\n",
        "\n",
        "By employing matrix operations, the gradient descent algorithm can efficiently update the weights in the direction of the steepest decrease of the cost function, enabling faster convergence to the optimal solution.\n",
        "\n",
        " If numerical instability is found in the gradient descent implementation, a common reason for this is when the learning rate is too large, causing the algorithm to overshoot the minimum, or when the features have significantly different scales, which can lead to convergence issues.\n",
        " To address this issue, we can try **normalizing** the input features. Normalizing the features typically involves scaling them so that they have a mean of 0 and a standard deviation of 1. This can help improve the convergence of the gradient descent algorithm."
      ],
      "metadata": {
        "id": "mocTdZ3JRYxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Simulating data for 100 patients\n",
        "num_patients = 100\n",
        "\n",
        "# Creating synthetic data for features and target variable\n",
        "molecular_weight = np.random.uniform(100, 500, num_patients)\n",
        "solubility = np.random.uniform(0.1, 0.9, num_patients)\n",
        "clinical_data = np.random.randint(1, 4, num_patients)  # 1, 2, 3 representing different clinical trial phases\n",
        "patient_age = np.random.randint(18, 80, num_patients)\n",
        "bioactivity = 0.5 * molecular_weight + 0.8 * solubility + 0.1 * clinical_data + np.random.normal(0, 10, num_patients)\n",
        "\n",
        "# Creating the 2D array\n",
        "data = np.column_stack((molecular_weight, solubility, clinical_data, patient_age, bioactivity))\n",
        "\n",
        "# Column names for the features\n",
        "column_names = ['Intercept', 'Molecular Weight', 'Solubility', 'Clinical Data', 'Patient Age']\n",
        "\n",
        "# Extracting features and the target variable\n",
        "X = data[:, :-1]  # Features\n",
        "y = data[:, -1]  # Target variable\n",
        "\n",
        "# Adding an intercept term by appending a column of ones to the feature matrix\n",
        "X_with_intercept = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "# Gradient Descent\n",
        "def gradient_descent(X, y, learning_rate, iterations):\n",
        "    # Getting the number of samples and features from the feature matrix X\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # Initializing the weights to zeros\n",
        "    weights = np.zeros(n_features)\n",
        "\n",
        "    # Performing the gradient descent for the specified number of iterations\n",
        "    for _ in range(iterations):\n",
        "        # Predicting the target variable using the current weights\n",
        "        y_pred = np.dot(X, weights)\n",
        "\n",
        "        # Calculating the difference between the predicted and actual target values\n",
        "        residuals = y_pred - y\n",
        "\n",
        "        # Calculating the gradient using the derivative of the mean squared error\n",
        "        # The gradient is the vector that points in the direction of the steepest increase of the function\n",
        "        gradient =  np.dot(X.T, residuals)\n",
        "\n",
        "        # Updating the weights in the opposite direction of the gradient to minimize the error\n",
        "        # The learning rate controls the size of the step taken during each iteration\n",
        "        weights -= learning_rate * gradient/ n_samples\n",
        "\n",
        "    # Returning the final weights\n",
        "    return weights\n",
        "\n",
        "# Normalizing the features\n",
        "X_normalized = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# Adding an intercept term by appending a column of ones to the normalized feature matrix\n",
        "X_normalized_with_intercept = np.c_[np.ones(X_normalized.shape[0]), X_normalized]\n",
        "\n",
        "# Setting the hyperparameters\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "# Computing the weights using the gradient descent algorithm\n",
        "weights = gradient_descent(X_normalized_with_intercept, y, learning_rate, iterations)\n",
        "\n",
        "# Computing the predicted y values\n",
        "y_pred = np.dot(X_normalized_with_intercept, weights)\n",
        "\n",
        "# Computing the mean squared error\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "\n",
        "# Computing the R-squared value\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Printing the weights\n",
        "print(\"Weights using Gradient Descent:\")\n",
        "print(weights)\n",
        "\n",
        "# Printing the column names and corresponding beta values\n",
        "print(\"Corresponding Beta Values:\")\n",
        "for i in range(len(column_names)):\n",
        "    print(f\"{column_names[i]}: {weights[i]}\")\n",
        "\n",
        "# Printing the MSE and R-squared value\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLIKdUoB5ZMc",
        "outputId": "faf3d7f9-dd97-4d09-db07-632b4f0a77f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights using Gradient Descent:\n",
            "[ 1.44499923e+02  5.83007009e+01  2.80616048e-02 -5.63075578e-01\n",
            " -4.82072621e-01]\n",
            "Corresponding Beta Values:\n",
            "Intercept: 144.4999234498233\n",
            "Molecular Weight: 58.300700933269624\n",
            "Solubility: 0.02806160478290335\n",
            "Clinical Data: -0.5630755778924973\n",
            "Patient Age: -0.48207262122824607\n",
            "MSE: 112.9555695267165\n",
            "R-squared: 0.9679268664286391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Gradient Descent with Cost Tracking\n",
        "def gradient_descent_with_cost_tracking(X, y, learning_rate, iterations):\n",
        "    n_samples, n_features = X.shape\n",
        "    weights = np.zeros(n_features)\n",
        "    costs = []  # List to store costs during iterations\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        y_pred = np.dot(X, weights)\n",
        "        residuals = y_pred - y\n",
        "        gradient = np.dot(X.T, residuals)\n",
        "        weights -= learning_rate * gradient / n_samples\n",
        "\n",
        "        # Calculating cost (mean squared error) and appending it to the list\n",
        "        cost = np.mean((y_pred - y) ** 2) / (2 * n_samples)\n",
        "        costs.append(cost)\n",
        "\n",
        "    return weights, costs\n",
        "\n",
        "# Computing the weights and tracking the cost during iterations\n",
        "weights, costs = gradient_descent_with_cost_tracking(X_normalized_with_intercept, y, learning_rate, iterations)\n",
        "\n",
        "# Plotting the cost function over iterations\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(iterations), costs, color='b')\n",
        "plt.title('Cost Function Over Iterations')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "tOWfKF1WMbm0",
        "outputId": "2731b469-5d20-43e5-d992-c0b4abacf849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularization\n",
        "\n",
        "7. **Regularizer Selection (Optional)**:\n",
        "\n",
        "We can improve the training set accuracy by adding new features as transfomations of the orginal columns of the datset. For example, we can add polynomial transformations to the feature set and perform polynomial regression. Polynomial regressoin is achieved by defining the feature map as:\n",
        "\n",
        "$$ ψ(x) = \\begin{bmatrix} 1 \\\\ x \\\\ x^2 \\\\ x^3 \\end{bmatrix}$$\n",
        "\n",
        "The polynomial regression model can then be represented as:\n",
        "$$y = w^T\\psi(x)$$\n",
        "\n",
        "\n",
        "The degree of the polynomial serves as a hyperparameter. Tuning this hyperparameter can be done using a validation set. However, limiting the size of the model is a simple solution and might hinder the ability to learn a more complex model, even when the data support it. An alternative approach is to maintain a large model but to regularize it.\n",
        "\n",
        "**L2 Regularization:**\n",
        "\n",
        "The observation is that polynomials that overfit often possess large coefficients. To encourage small weights, we can opt for the $L2$ penalty as our regularizer. Note that to be pedantic, the $L2$ norm represents the Euclidean distance. The $L2$ norm represents the Euclidean distance.\n",
        "\n",
        "$R(w) = \\frac{1}{2} \\lVert w \\rVert_2^2 = \\frac{1}{2} \\sum w_j^2$\n",
        "\n",
        " where $\\|w\\|_2^2$ is the squared L2 norm of the weight vector.\n",
        "\n",
        "We are regularizing the squared $L2$ norm. The regularized cost function strikes a balance between the fit to the data and the norm of the weights and is given by:\n",
        "\n",
        "$$J_{\\text{reg}} = J + \\lambda R = J + \\frac{\\lambda}{2} \\sum w_j^2$$\n",
        "\n",
        "Here, $\\lambda$ serves as a hyperparameter that can be tuned using a validation set.\n",
        "\n",
        "$J_{\\text{reg}} = J + \\lambda R = J + \\lambda \\frac{1}{2} \\|w\\|_2^2$,\n",
        "\n",
        "where 'J' is the original cost function and $\\lambda$ is the regularization parameter that can be tuned using a validation set.\n",
        "\n",
        "All the derivations for the gradient descent algorithms discussed thus far remain exactly the same.\n",
        "\n",
        "Recalling the gradient descent update:\n",
        "$$w = w - \\alpha \\frac{\\partial J}{\\partial w}$$\n",
        "\n",
        "The gradient descent update for the regularized cost has an interesting interpretation as weight decay:\n",
        "$$w = w - \\alpha \\left( \\frac{\\partial J}{\\partial w} + \\lambda \\frac{\\partial R}{\\partial w} \\right) = w - \\alpha \\left( \\frac{\\partial J}{\\partial w} + \\lambda w \\right) = (1 - \\alpha \\lambda)w - \\alpha \\frac{\\partial J}{\\partial w}$$\n",
        "\n",
        "This interpretation illustrates that the gradient descent update accounts for weight decay, a method used to regularize or constrain the complexity of a model by adding a penalty term to the loss function. The term \\($\\lambda w$\\) acts as a regularizing term that discourages large weights. The update rule shrinks the weight by a factor of \\($1 - \\alpha \\lambda$\\) and moves it in the direction of the **negative** gradient, scaled by the learning rate \\($\\alpha$\\). This allows for a balance between fitting the data and preventing overfitting."
      ],
      "metadata": {
        "id": "NGuhY8hR9q_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Gradient Descent with L2 Regularization\n",
        "def gradient_descent_with_L2(X, y, learning_rate, iterations, l2_penalty):\n",
        "    # Getting the number of samples and features from the feature matrix X\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # Initializing the weights to zeros\n",
        "    weights = np.zeros(n_features)\n",
        "\n",
        "    # Performing the gradient descent for the specified number of iterations\n",
        "    for _ in range(iterations):\n",
        "        # Predicting the target variable using the current weights\n",
        "        y_pred = np.dot(X, weights)\n",
        "\n",
        "        # Calculating the difference between the predicted and actual target values\n",
        "        residuals = y_pred - y\n",
        "\n",
        "        # Calculating the gradient using the derivative of the mean squared error\n",
        "        gradient = np.dot(X.T, residuals)\n",
        "\n",
        "        # Updating the weights with the regularization term\n",
        "        weights = (1 - learning_rate * l2_penalty) * weights - learning_rate * gradient / n_samples\n",
        "\n",
        "    # Returning the final weights\n",
        "    return weights\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Simulating data for 100 patients\n",
        "num_patients = 100\n",
        "\n",
        "# Creating synthetic data for features and target variable\n",
        "molecular_weight = np.random.uniform(100, 500, num_patients)\n",
        "solubility = np.random.uniform(0.1, 0.9, num_patients)\n",
        "clinical_data = np.random.randint(1, 4, num_patients)  # 1, 2, 3 representing different clinical trial phases\n",
        "patient_age = np.random.randint(18, 80, num_patients)\n",
        "bioactivity = 0.5 * molecular_weight + 0.8 * solubility + 0.1 * clinical_data + np.random.normal(0, 10, num_patients)\n",
        "\n",
        "# Creating the 2D array\n",
        "data = np.column_stack((molecular_weight, solubility, clinical_data, patient_age, bioactivity))\n",
        "\n",
        "# Column names for the features\n",
        "column_names = ['Intercept', 'Molecular Weight', 'Solubility', 'Clinical Data', 'Patient Age']\n",
        "\n",
        "# Extracting features and the target variable\n",
        "X = data[:, :-1]  # Features\n",
        "y = data[:, -1]  # Target variable\n",
        "\n",
        "# Creating polynomial features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Normalizing the polynomial features\n",
        "X_poly_normalized = (X_poly - np.mean(X_poly, axis=0)) / np.std(X_poly, axis=0)\n",
        "\n",
        "# Adding an intercept term by appending a column of ones to the normalized polynomial feature matrix\n",
        "X_poly_normalized_with_intercept = np.c_[np.ones(X_poly_normalized.shape[0]), X_poly_normalized]\n",
        "\n",
        "# Setting the hyperparameters\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "l2_penalty = 0.1\n",
        "\n",
        "# Computing the weights using the gradient descent algorithm with L2 regularization\n",
        "weights_with_L2_poly = gradient_descent_with_L2(X_poly_normalized_with_intercept, y, learning_rate, iterations, l2_penalty)\n",
        "\n",
        "# Computing the predicted y values\n",
        "y_pred = np.dot(X_poly_normalized_with_intercept, weights_with_L2_poly)\n",
        "\n",
        "# Computing the mean squared error\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "\n",
        "# Computing the R-squared value\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "\n",
        "# Printing the weights with L2 regularization for polynomial features\n",
        "print(\"Weights using Gradient Descent with L2 Regularization for Polynomial Features:\")\n",
        "print(weights_with_L2_poly)\n",
        "\n",
        "# Printing the column names and corresponding beta values with L2 regularization for polynomial features\n",
        "print(\"Corresponding Beta Values with L2 Regularization for Polynomial Features:\")\n",
        "poly_column_names = poly.get_feature_names_out(input_features=column_names[1:])  # Excluding the intercept\n",
        "for i in range(len(poly_column_names)):\n",
        "    print(f\"{poly_column_names[i]}: {weights_with_L2_poly[i+1]}\")\n",
        "\n",
        "# Printing the MSE and R-squared value\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j5K59JWIOEmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7116f4cb-a59c-48cb-bc40-eb0c6f22e8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights using Gradient Descent with L2 Regularization for Polynomial Features:\n",
            "[131.36717379  19.58952608  -1.27101558  -1.94739389  -3.14366691\n",
            "  18.21569305   6.11777138   7.75241955  12.87671188  -0.9969055\n",
            "  -1.56663892  -0.53650769  -0.41757969  -4.10463796  -2.9332886 ]\n",
            "Corresponding Beta Values with L2 Regularization for Polynomial Features:\n",
            "Molecular Weight: 19.589526075188058\n",
            "Solubility: -1.2710155834523629\n",
            "Clinical Data: -1.9473938916394704\n",
            "Patient Age: -3.14366691455163\n",
            "Molecular Weight^2: 18.21569305119155\n",
            "Molecular Weight Solubility: 6.117771382263281\n",
            "Molecular Weight Clinical Data: 7.752419552549612\n",
            "Molecular Weight Patient Age: 12.876711883050321\n",
            "Solubility^2: -0.996905501873758\n",
            "Solubility Clinical Data: -1.5666389189631296\n",
            "Solubility Patient Age: -0.5365076878077755\n",
            "Clinical Data^2: -0.41757968502544657\n",
            "Clinical Data Patient Age: -4.10463795587623\n",
            "Patient Age^2: -2.933288596715273\n",
            "MSE: 289.621832695148\n",
            "R-squared: 0.9177634200408618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Neural Networks\n",
        "\n",
        "## Overview\n",
        "Neural networks, inspired by the human brain's structure and functionality, are a powerful class of machine learning models used for a variety of tasks, including pattern recognition, classification, regression, and more. With their ability to learn complex relationships from data, neural networks have become a fundamental tool in the field of artificial intelligence. In this lecture, we will explore the basics of neural networks, their architecture, training process, and various types, providing a comprehensive understanding of their inner workings and applications.\n",
        "\n",
        "## What is a Neural Network?\n",
        "A neural network is a computational model composed of interconnected nodes (neurons) organized in layers. Each neuron processes input data, applies an activation function, and passes the output to the next layer. The strength of neural networks lies in their capability to learn intricate patterns and relationships from data, enabling them to make predictions, classifications, and decisions.\n",
        "\n",
        "## Neural Network Architecture\n",
        "1. Input Layer: The initial layer that receives the input data.\n",
        "2. Hidden Layers: Intermediate layers that process data through weighted connections and apply non-linear transformations.\n",
        "3. Output Layer: The final layer that produces the network's output.\n",
        "\n",
        "## Neural Network Training Process\n",
        "1. Forward Propagation: Input data is fed through the network, and computations occur layer by layer until the output is generated.\n",
        "2. Loss Calculation: The discrepancy between the predicted output and the actual output is computed using a predefined loss function.\n",
        "3. Backward Propagation (Backpropagation): The gradients of the loss function with respect to the network's parameters are calculated. These gradients are used to adjust the weights and biases in the network to minimize the loss function.\n",
        "4. Optimization: Various optimization algorithms, such as gradient descent and its variants, are used to update the network's parameters iteratively, aiming to find the optimal values that minimize the loss function.\n",
        "\n",
        "## Types of Neural Networks\n",
        "1. Feedforward Neural Networks (FNNs): Basic neural networks where data flows only in one direction, from the input to the output.\n",
        "2. Convolutional Neural Networks (CNNs): Specialized for processing grid-structured data, such as images, using convolutional and pooling layers.\n",
        "3. Recurrent Neural Networks (RNNs): Designed to handle sequential data by retaining information in the form of hidden states, allowing them to learn temporal dependencies.\n",
        "4. Long Short-Term Memory Networks (LSTMs): A type of RNN that can capture long-term dependencies and mitigate the vanishing gradient problem.\n",
        "5. Generative Adversarial Networks (GANs): Comprising a generator and a discriminator, GANs are used to generate new data instances that resemble the training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "kA5Jbv1aX13I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structure of Neural Networks\n",
        "\n",
        "The artificial neuron has N inputs, each denoted as $u_1, u_2, ..., u_N,$ with corresponding weights $w_1, w_2, ..., w_N$ representing the synaptic connections in biological neurons. The threshold, typically denoted as θ, is used to determine whether the neuron fires or not. The activation of the neuron is determined by the formula:\n",
        "\n",
        "$$z = \\sum_{j=1}^{N} w_j u_j + \\theta $$\n",
        "\n",
        "In vector notation:\n",
        "$$z = w^Tu + \\theta$$\n",
        "\n",
        "In the context of the artificial neuron model, a negative weight indicates an inhibitory connection, while a positive weight indicates an excitatory one. The threshold θ may be assigned a positive value, known as bias. Sometimes, for mathematical convenience, the threshold is combined into the summation part by assuming an imaginary input \\($u_0 = 1$\\) and a connection weight \\($w_0 = \\theta\\$), leading to the simplified activation formula:c\n",
        "\n",
        "$z = \\sum_{j=0}^{N} w_j u_j $\n",
        "\n",
        "\n",
        "The output of the neuron, denoted by \\(x\\), is determined by a function of the activation, \\(f(a)\\), which can take various forms such as the threshold function, linear function, ramp function, sigmoid function or ReLU function.\n",
        "\n",
        "\n",
        "1. Linear: The linear function is denoted as $$f(a) = \\kappa a,$$\n",
        "\n",
        "    where \\($\\kappa$\\) is a constant.\n",
        "\n",
        "2. Threshold: The threshold function is defined as follows:\n",
        "  $$\n",
        "   f(z) = \\begin{cases}\n",
        "            0 & \\text{if } z \\leq 0, \\\\\n",
        "            1 & \\text{if } z > 0\n",
        "          \\end{cases}\n",
        "  $$\n",
        "   It effectively acts as a step function, producing a binary output based on whether the activation is greater than zero or not.\n",
        "\n",
        "3. Ramp: The ramp function is defined as:\n",
        "   $$\n",
        "   f(z) = \\begin{cases}\n",
        "            0 & \\text{if } z \\leq 0, \\\\\n",
        "            z & \\text{if } 0 < z < 1, \\\\\n",
        "            1 & \\text{if } z \\geq 1\n",
        "          \\end{cases}\n",
        "   $$\n",
        "\n",
        "4. Sigmoid: The sigmoid function is expressed as:\n",
        "  $$\n",
        "   f(z) = \\frac{1}{1 + e^{-\\kappa z}}\n",
        "   $$\n",
        "   where \\(\\kappa\\) is a constant. The sigmoid function is commonly used in neural networks for its smooth, S-shaped curve that allows for gradient-based optimization during training.\n",
        "\n",
        "5. ReLU (Rectified Linear Unit): The ReLU function is represented as:\n",
        "   \n",
        "  $$\n",
        "   f(z) = \\max(0, z)\n",
        "  $$\n",
        "\n",
        "   The ReLU function returns the input directly if it is positive and zero otherwise. This function helps address the vanishing gradient problem and allows the network to learn complex patterns and relationships in the data. It is widely used in many deep learning models due to its simplicity and effectiveness.\n",
        "\n",
        "A **neural network** is formed by connecting the outputs of multiple artificial neurons to create a complex system capable of implementing various functions. In this network, each neuron is assigned an index to distinguish it from others. The activation of the \\(i\\)th neuron is expressed using the modified formula:\n",
        "\n",
        "$$z_i = \\sum_{j=1}^{N} w_{ji}x_j + \\theta_i $$\n",
        "\n",
        "Here, \\($x_j$\\) can either represent the output of another neuron, determined as \\($x_j = f(z_j$)\\) or an external input represented by \\($u_j$\\).\n",
        "\n",
        "The components in this formula are as follows:\n",
        "\n",
        "- $z_i$ is the activation of the $i$th neuron in the network.\n",
        "- $w_{ji}$ denotes the weight associated with the connection between the $j$th neuron and the $i$th neuron.\n",
        "- $x_j$ represents either the output of the $j$th neuron or an external input, as described earlier.\n",
        "- $\\theta_i$ is the threshold associated with the $i$th neuron.\n",
        "\n",
        "This modification allows for the consideration of the outputs of other neurons within the network as inputs for a given neuron. By interconnecting multiple artificial neurons in this manner, complex computations and functions can be implemented, overcoming the limitations of a single artificial neuron in performing certain tasks.\n",
        "\n",
        "For the neural network, a state vector $x$ is defined, where the $i$th component represents the output of the $i$th neuron, denoted as $x_i$. Additionally, a weight matrix $W$ is defined, where the component $w_{ji}$ represents the weight of the connection from neuron $j$ to neuron $i$. With these definitions, the system can be represented as:\n",
        "\n",
        "$$z = f(W^T \\cdot x + \\theta)$$\n",
        "\n",
        "Here, $\\theta$ is the vector whose $i$th component is $\\theta_i$, and $f$ is used to denote the vector function, where $f_i$ is applied to the $i$th component of the vector. This representation captures the dynamics of the neural network, where $a_i$ of each neuron is determined based on the weighted sum of the inputs, including the threshold values, and the application of the respective transfer functions. This formulation allows for the analysis and understanding of the behavior of the neural network as a whole.\n"
      ],
      "metadata": {
        "id": "uPb_NJz5fPYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of neural networks, the training process involves adjusting the weights and biases to minimize the error between the predicted output and the actual output. The process typically involves the following steps:\n",
        "\n",
        "1. **Forward Propagation**: During forward propagation, the inputs are fed into the network, and the network computes the activations and outputs of each neuron successively using the provided formulas.\n",
        "\n",
        "    The activation of the \\(i\\)th neuron is determined by the formula:\n",
        "    \\[a_i = \\sum_{j=1}^{N} w_{ji}x_j + \\theta_i\\]\n",
        "    where \\(x_j\\) can either represent the output of another neuron, \\(x_j = f(a_j)\\), or an external input represented by \\(u_j\\).\n",
        "\n",
        "2. **Activation Function Application**: After the forward propagation step, the output of each neuron is passed through an activation function to introduce non-linearity into the network. Various activation functions can be used, such as the linear function, threshold function, ramp function, sigmoid function, or ReLU function, based on the requirements of the problem and the desired properties of the network.\n",
        "\n",
        "3. **Error Computation**: Once the network generates the output, the error between the predicted output and the actual output is calculated using a suitable error function, such as mean squared error or cross-entropy loss.\n",
        "\n",
        "4. **Backward Propagation (Backpropagation)**: Backpropagation is the process of calculating the gradients of the error with respect to the weights and biases of the network. This process helps in understanding how a change in each weight and bias influences the overall error. These gradients are then used to update the weights and biases in a way that minimizes the error.\n",
        "\n",
        "5. **Update Weights and Biases**: The weights and biases are updated using optimization techniques such as gradient descent, stochastic gradient descent, or their variants. These methods help adjust the parameters in a way that moves the network in the direction of minimizing the error.\n",
        "\n",
        "6. **Iterations**: Steps 1 to 5 are iterated multiple times, with the network making gradual adjustments to the weights and biases to minimize the error. The number of iterations depends on the complexity of the problem, the size of the dataset, and the convergence criteria set by the user.\n",
        "\n",
        "By iteratively adjusting the weights and biases through forward and backward propagation, the neural network can learn the underlying patterns and relationships in the data and improve its predictive capabilities. The trained network can then be used to make predictions on new, unseen data."
      ],
      "metadata": {
        "id": "B7IoGQ58qp76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of the sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "# Generating synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(1000, 4)  # Input features\n",
        "y = np.random.rand(1000, 1)  # Target variable\n",
        "\n",
        "# Initialize weights randomly with mean 0\n",
        "input_size = 4\n",
        "hidden_size = 5\n",
        "output_size = 1\n",
        "\n",
        "weights_input_hidden = np.random.uniform(size=(input_size, hidden_size))  # Weights from input to hidden layer\n",
        "weights_hidden_output = np.random.uniform(size=(hidden_size, output_size))  # Weights from hidden to output layer\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.1\n",
        "epochs = 1000\n",
        "\n",
        "# Training the neural network\n",
        "for epoch in range(epochs):\n",
        "    # Forward Propagation\n",
        "    hidden_layer_input = np.dot(X, weights_input_hidden)  # Computing the input to the hidden layer\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)  # Applying the activation function to the hidden layer input\n",
        "\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)  # Computing the input to the output layer\n",
        "    predicted_output = sigmoid(output_layer_input)  # Applying the activation function to the output layer input\n",
        "\n",
        "    # Backpropagation\n",
        "    error = y - predicted_output  # Calculating the error between the predicted and actual output\n",
        "    d_predicted_output = error * sigmoid_derivative(predicted_output)  # Calculating the derivative of the predicted output\n",
        "\n",
        "    error_hidden_layer = d_predicted_output.dot(weights_hidden_output.T)  # Calculating the error at the hidden layer\n",
        "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)  # Calculating the derivative at the hidden layer\n",
        "\n",
        "    # Updating Weights\n",
        "    weights_hidden_output += hidden_layer_output.T.dot(d_predicted_output) * learning_rate  # Updating weights between hidden and output layers\n",
        "    weights_input_hidden += X.T.dot(d_hidden_layer) * learning_rate  # Updating weights between input and hidden layers\n",
        "\n",
        "# Printing the final predicted output\n",
        "print(\"Predicted Output after Training:\")\n",
        "#print(predicted_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBlBel5vY4nj",
        "outputId": "ae993881-e112-40fc-cccb-beb65c42407c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Output after Training:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(1000, 4)  # 1000 data points with 4 features\n",
        "weights_input_hidden = np.random.rand(4, 5)  # Weight matrix from input to hidden layer\n",
        "weights_hidden_output = np.random.rand(5, 1)  # Weight matrix from hidden to output layer\n",
        "bias_hidden = np.random.rand(1, 5)  # Bias for the hidden layer\n",
        "bias_output = np.random.rand(1)  # Bias for the output layer\n",
        "y = np.random.rand(1000, 1)  # Target variable\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Forward propagation\n",
        "hidden_layer_activation = np.dot(X, weights_input_hidden) + bias_hidden\n",
        "hidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "output_layer_activation = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
        "predicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "# Error computation\n",
        "error = np.mean((predicted_output - y) ** 2)\n",
        "\n",
        "# Backward propagation (Backpropagation) - Assuming a simple update rule for demonstration\n",
        "output_error = (predicted_output - y) * (predicted_output * (1 - predicted_output))\n",
        "hidden_error = np.dot(output_error, weights_hidden_output.T) * (hidden_layer_output * (1 - hidden_layer_output))\n",
        "\n",
        "# Gradient descent - Assuming a simple learning rate for demonstration\n",
        "learning_rate = 0.1\n",
        "weights_hidden_output -= learning_rate * np.dot(hidden_layer_output.T, output_error)\n",
        "weights_input_hidden -= learning_rate * np.dot(X.T, hidden_error)\n",
        "bias_output -= learning_rate * np.sum(output_error)\n",
        "bias_hidden -= learning_rate * np.sum(hidden_error)\n",
        "\n",
        "# Iterations - Repeat the process for multiple iterations\n",
        "num_iterations = 100\n",
        "for i in range(num_iterations):\n",
        "    # Forward propagation\n",
        "    hidden_layer_activation = np.dot(X, weights_input_hidden) + bias_hidden\n",
        "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "    output_layer_activation = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
        "    predicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "    # Backward propagation\n",
        "    output_error = (predicted_output - y) * (predicted_output * (1 - predicted_output))\n",
        "    hidden_error = np.dot(output_error, weights_hidden_output.T) * (hidden_layer_output * (1 - hidden_layer_output))\n",
        "\n",
        "    # Gradient descent\n",
        "    weights_hidden_output -= learning_rate * np.dot(hidden_layer_output.T, output_error)\n",
        "    weights_input_hidden -= learning_rate * np.dot(X.T, hidden_error)\n",
        "    bias_output -= learning_rate * np.sum(output_error)\n",
        "    bias_hidden -= learning_rate * np.sum(hidden_error)\n",
        "\n",
        "    # Error computation\n",
        "    error = np.mean((predicted_output - y) ** 2)\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"Iteration {i + 1}, Error: {error:.4f}\")\n",
        "\n",
        "# Final predictions\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(predicted_output)"
      ],
      "metadata": {
        "id": "AwXJYUT7rhwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Cross Entropy\n",
        "Binary Cross Entropy (BCE) is a widely used loss function for binary classification tasks. It measures the difference between the predicted probability distribution and the actual binary label. BCE is particularly useful when dealing with binary classification problems where the task is to predict whether an instance belongs to one class or another.\n",
        "\n",
        "The Binary Cross Entropy loss function is based on the concept of information entropy from information theory. It quantifies the difference between two probability distributions, the true distribution and the predicted distribution. It penalizes the model more for larger differences between the predicted and actual values, making it a suitable choice for training models in binary classification tasks.\n",
        "\n",
        "The formula for BCE is:\n",
        "\n",
        "$$BCE = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\cdot \\log(\\hat{y}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{y}_i)]$$\n",
        "\n",
        "where $N$ is the number of observations, $y_i$ is the actual value (0 or 1), and $\\hat{y}_i$ is the predicted probability.\n",
        "\n",
        "It is important to note that the BCE penalizes the model logarithmically for misclassifications. Specifically, it heavily penalizes high-confidence incorrect predictions and low-confidence incorrect predictions, while barely penalizing high-confidence correct predictions. This characteristic makes it a well-suited loss function for binary classification problems, ensuring that the model learns to predict probabilities as close to the true labels as possible.\n",
        "\n",
        "Now, let's calculate the Binary Cross Entropy for a subset of 5 observations using the provided table.\n",
        "\n",
        "Here is the modified table with 5 observations:\n",
        "\n",
        "| Observation Number | Actual Value (0 or 1) | Predicted Probability |\n",
        "|--------------------|-----------------------|-----------------------|\n",
        "| 1                  | 0                     | 0.3                   |\n",
        "| 2                  | 1                     | 0.7                   |\n",
        "| 3                  | 0                     | 0.4                   |\n",
        "| 4                  | 1                     | 0.6                   |\n",
        "| 5                  | 1                     | 0.8                   |\n",
        "\n",
        "Now, let's calculate the Binary Cross Entropy (BCE) for these 5 observations using the formula:\n",
        "\n",
        "$$BCE = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\cdot \\log(\\hat{y}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{y}_i)]$$\n",
        "\n",
        "where $N$ is the number of observations, $y_i$ is the actual value (0 or 1), and $\\hat{y}_i$ is the predicted probability.\n",
        "\n",
        "For the first observation:\n",
        "\n",
        "$$BCE_1 = -[0 \\cdot \\log(0.3) + (1 - 0) \\cdot \\log(1 - 0.3)]$$\n",
        "\n",
        "For the second observation:\n",
        "\n",
        "$$BCE_2 = -[1 \\cdot \\log(0.7) + (1 - 1) \\cdot \\log(1 - 0.7)]$$\n",
        "\n",
        "For the third observation:\n",
        "\n",
        "$$BCE_3 = -[0 \\cdot \\log(0.4) + (1 - 0) \\cdot \\log(1 - 0.4)]$$\n",
        "\n",
        "For the fourth observation:\n",
        "\n",
        "$$BCE_4 = -[1 \\cdot \\log(0.6) + (1 - 1) \\cdot \\log(1 - 0.6)]$$\n",
        "\n",
        "For the fifth observation:\n",
        "\n",
        "$$BCE_5 = -[1 \\cdot \\log(0.8) + (1 - 1) \\cdot \\log(1 - 0.8)]$$\n",
        "\n",
        "After calculating the BCE for each observation, we can take the average of all the $BCE$ values to obtain the overall Binary Cross Entropy."
      ],
      "metadata": {
        "id": "9w6K2mygrYl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the data\n",
        "data = np.array([\n",
        "    [0, 0.3],\n",
        "    [1, 0.7],\n",
        "    [0, 0.4],\n",
        "    [1, 0.6],\n",
        "    [1, 0.8]\n",
        "])\n",
        "\n",
        "# Extract the actual values and predicted probabilities\n",
        "y = data[:, 0]\n",
        "y_hat = data[:, 1]\n",
        "\n",
        "# Calculate the BCE for each observation\n",
        "BCE = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
        "\n",
        "# Print the results\n",
        "print(\"Binary Cross Entropy (BCE):\", BCE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg8DsvATs2lU",
        "outputId": "08a11bb2-7d77-400e-8cff-87dd7652cc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Cross Entropy (BCE): 0.3916289373447312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Entropy Loss\n",
        "\n",
        "The Binary Cross Entropy (BCE) loss function is used for binary classification problems, where the goal is to predict whether an instance belongs to one class or another. If the softmax function is used for multi-class classification with $m$ classes, the Cross Entropy Loss (CE) is typically employed, which is an extension of the BCE for the multi-class case.\n",
        "\n",
        "The Cross Entropy Loss for multi-class classification with the softmax function is expressed as follows:\n",
        "\n",
        "$CE(y, \\hat{y}) = - \\frac{1}{N}\\sum_{i=1}^{m} y_i \\log(\\hat{y}_i)$\n",
        "\n",
        "where:\n",
        "- $N$ is the number of observations.\n",
        "- $y$ is a one-hot encoded vector representing the true class label, with $m$ elements where all elements are 0 except for the true class label, which is 1.\n",
        "- $\\hat{y}$ is the vector of predicted probabilities for each class, obtained using the softmax function. It represents the probability distribution over the $m$ classes.\n",
        "\n",
        "The Cross Entropy Loss penalizes the model based on the difference between the true distribution ($y$) and the predicted distribution ($\\hat{y}$). It aims to minimize the difference between the predicted probabilities and the true labels. The model tries to improve by adjusting its parameters to reduce the Cross Entropy Loss, thereby increasing the accuracy of the predictions.\n",
        "\n",
        "Let's consider an example with 5 observations and 3 classes for the Cross Entropy loss calculation. We denote the actual one-hot encoded labels as $y$ and the predicted probability distributions as $\\hat{y}$.\n",
        "\n",
        "Suppose we have the following data:\n",
        "\n",
        "Observation 1: $\\mathbf{y} = [1, 0, 0]$, $\\hat{\\mathbf{y}} = [0.7, 0.2, 0.1]$\n",
        "\n",
        "Observation 2: $\\mathbf{y} = [0, 1, 0]$, $\\hat{\\mathbf{y}} = [0.3, 0.5, 0.2]$\n",
        "\n",
        "Observation 3: $\\mathbf{y} = [0, 0, 1]$, $\\hat{\\mathbf{y}} = [0.2, 0.1, 0.7]$\n",
        "\n",
        "Observation 4: $\\mathbf{y} = [1, 0, 0]$, $\\hat{\\mathbf{y}} = [0.4, 0.4, 0.2]$\n",
        "\n",
        "Observation 5: $\\mathbf{y} = [0, 1, 0]$, $\\hat{\\mathbf{y}} = [0.2, 0.6, 0.2]$\n",
        "\n",
        "Let's plug these values into the Cross Entropy loss formula for each observation:\n",
        "\n",
        "Observation 1:\n",
        "$CE_1 = -\\sum_{i=1}^{3} y_{1i} \\log(\\hat{y}_{1i}) = -1 \\cdot \\log(0.7) = -\\log(0.7)$\n",
        "\n",
        "Observation 2:\n",
        "$CE_2 = -\\sum_{i=1}^{3} y_{2i} \\log(\\hat{y}_{2i}) = -1 \\cdot \\log(0.5) = -\\log(0.5)$\n",
        "\n",
        "Observation 3:\n",
        "$CE_3 = -\\sum_{i=1}^{3} y_{3i} \\log(\\hat{y}_{3i}) = -1 \\cdot \\log(0.7) = -\\log(0.7)$\n",
        "\n",
        "Observation 4:\n",
        "$CE_4 = -\\sum_{i=1}^{3} y_{4i} \\log(\\hat{y}_{4i}) = -1 \\cdot \\log(0.4) = -\\log(0.4)$\n",
        "\n",
        "Observation 5:\n",
        "$CE_5 = -\\sum_{i=1}^{3} y_{5i} \\log(\\hat{y}_{5i}) = -1 \\cdot \\log(0.6) = -\\log(0.6)$\n",
        "\n",
        "After calculating the CE for each observation, we can take the average of all the $CE$ values to obtain the overall Cross Entropy."
      ],
      "metadata": {
        "id": "R4O5kZibugEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# True labels (one-hot encoded)\n",
        "y = np.array([[1, 0, 0],\n",
        "              [0, 1, 0],\n",
        "              [0, 0, 1],\n",
        "              [1, 0, 0],\n",
        "              [0, 1, 0]])\n",
        "\n",
        "# Predicted probabilities\n",
        "y_hat = np.array([[0.7, 0.2, 0.1],\n",
        "                  [0.3, 0.5, 0.2],\n",
        "                  [0.2, 0.1, 0.7],\n",
        "                  [0.4, 0.4, 0.2],\n",
        "                  [0.2, 0.6, 0.2]])\n",
        "\n",
        "# Compute Cross Entropy loss for each observation\n",
        "CE_loss = -np.sum(y * np.log(y_hat), axis=1)\n",
        "\n",
        "# Overall Cross Entropy\n",
        "print(f\"Overall Cross Entropy: CE = {np.mean(CE_loss)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i3DUpr6uh4l",
        "outputId": "cc1ff990-110d-405a-e171-0a4a1b4e6a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Cross Entropy: CE = 0.5667226848155111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation Algorithm\n",
        "\n",
        "The backpropagation algorithm is a fundamental technique in training artificial neural networks. It involves two distinct passes, the forward pass and the backward pass, through the layers of the network.\n",
        "\n",
        "# Summary of the Algorithm\n",
        "1. **Forward Pass:**\n",
        "   - The input data is propagated through the network, layer by layer, using the current weights and biases.\n",
        "   - For each neuron, the input is multiplied by the weights, and the bias is added. Then, the activation function is applied to the result to generate the output of that neuron.\n",
        "   - The output of the last layer is compared with the actual labels to compute the error.\n",
        "\n",
        "2. **Backward Pass:**\n",
        "   - The error is propagated backward through the network. This involves calculating the gradients of the error with respect to the weights and biases.\n",
        "   - Using the chain rule of calculus, the error at the output layer is used to compute the error at the previous layers, and so on until the first layer.\n",
        "   - The gradients are used to update the weights and biases to minimize the error. This is usually done using optimization techniques like gradient descent or its variants.\n",
        "\n",
        "3. **Iterations:**\n",
        "   - The forward and backward passes are repeated multiple times for different data points in the training dataset.\n",
        "   - The weights and biases are updated after each iteration to minimize the overall error.\n",
        "   - The process is repeated until a stopping criterion is met, which could be a maximum number of iterations or a threshold for the error.\n",
        "\n",
        "Additionally, it's crucial to preprocess the data and normalize it appropriately for numerical prediction tasks. This can ensure that the output values are within a reasonable range and help improve the performance of the network.\n",
        "\n",
        "## Details of Algorithm:\n",
        "\n",
        "Let's assume we have a single hidden layer with $n_{\\text{hidden}}$ neurons and an output layer.\n",
        "\n",
        "1. **Forward Pass:**\n",
        "   \n",
        "   For the $i$-th neuron in the hidden layer, the weighted sum is calculated as:\n",
        "   \n",
        "   $$z_i^{(\\text{hidden})} = \\sum_{j=1}^{n_{\\text{in}}} w_{ij}^{(\\text{hidden})}x_j^{(\\text{in})} + \\theta_i^{(\\text{hidden})}$$\n",
        "   \n",
        "\n",
        "  where\n",
        "  $z_i^{(\\text{hidden})}$ is the input of the $i$th hidden node before the activation function is applied.\n",
        "  $w_{ij}^{(\\text{hidden})}$ is the weight for the $j$th input node value for the $i$th hidden node.\n",
        "  $x_j^{(\\text{in})}$ is the $j$th input node value.\n",
        "  $\\theta_i^{(\\text{hidden})}$  is the bias for the $i$th hidden node.\n",
        "\n",
        "   Then, the activation function $f$ is applied. The activation function gives the outupt of the hidden layer which are the inputs to the output layer. The activation function could be different depending on the type of problem:\n",
        "   \n",
        "   - For classification problems, the commonly used activation function is the sigmoid function:\n",
        "     \n",
        "     $$a_i^{(\\text{hidden})} = \\frac{1}{1 + e^{-z_i^{(\\text{hidden})}}}$$\n",
        "     \n",
        "   - For continuous prediction problems, the identity function is used as the activation function:\n",
        "     \n",
        "     $$a_i^{(\\text{hidden})} = z_i^{(\\text{hidden})}$$\n",
        "\n",
        "   \n",
        "   The number of nodes in the output layer, denoted as $n_{\\text{out}}$, depends on the specific problem we are trying to solve. his number is determined by the requirements of the task at hand.\n",
        "- For a binary classification problem, you typically have a single node in the output layer, as the network is predicting the probability of belonging to one of the two classes.\n",
        "\n",
        "- For multi-class classification problems, the number of nodes in the output layer is equal to the number of classes you want to classify.\n",
        "\n",
        "- For regression problems, where you are predicting continuous values, you might have a single node in the output layer.\n",
        "   \n",
        "   \n",
        "In the case of **single-node** the output layer:\n",
        "\n",
        "a. For regression problems we have:\n",
        "   \n",
        "  $$z^{(\\text{out})} = \\sum_{i=1}^{n_{\\text{hidden}}} w_i^{(\\text{out})}a_i^{(\\text{hidden})} + \\theta^{(\\text{out})}$$\n",
        "\n",
        "   - For binary classification problems, if we are using a sigmoid activation function, then the output is given by:\n",
        "     \n",
        "     $$y = \\frac{1}{1 + e^{-z^{(\\text{out})}}}$$\n",
        "     \n",
        "   - For continuous prediction problems, the output of the network directly becomes the predicted value:\n",
        "     \n",
        "     $$y = z^{(\\text{out})}$$\n",
        "\n",
        "For multi-class classification problems, we have to take the number of classes to be the number of the output layer nodes.\n",
        "\n",
        " $$z_i^{(\\text{out})} = \\sum_{i=1}^{n_{\\text{hidden}}} w_{ij}^{(\\text{out})} a_i^{(\\text{hidden})} + \\theta_i^{(\\text{out})}$$\n",
        "\n",
        "Then, we have to use the softmax activation function. The probability of each class $j$ is given by:\n",
        "\n",
        "\n",
        "$$P(y=j|z) = \\frac{e^{z_j}}{\\sum_{i=1}^{n_{\\text{out}}} e^{z_i}}$$\n",
        "\n",
        "2. **Backward Pass:**\n",
        "\n",
        "The error function $E$ represents the discrepancy between the predicted output and the actual target values. The specific form of the error function depends on the task at hand, whether it's a classification problem or a regression problem.\n",
        "\n",
        "- For regression problems, where the goal is to predict a continuous numerical value, a commonly used error function is the Mean Squared Error (MSE). The MSE for a single prediction can be defined as:\n",
        "\n",
        "  $$E = \\frac{1}{2N_{\\text{obs}}}\\sum_{i=1}^{n_{\\text{obs}}}(y^{(i)} - t^{(i)})^2$$\n",
        "\n",
        "   where **$n_{\\text{obs}}$ is the number of data-points**, $t^{(i)}$ is the actual value, and $y^{(i)}$ is the predicted value for the data point $i$.\n",
        "\n",
        "- For the binary classification problems, where the goal is to assign a class label to the input data, a commonly used error function is the Cross-Entropy Loss. For a binary classification problem, the cross-entropy loss can be defined as:\n",
        "\n",
        "   $$E = -\\frac{1}{N_{\\text{obs}}}\\sum_{i=1}^{n_{\\text{obs}}}\\left({t}^{(i)}\\log(y^{(i)}) + (1 - {t}^{(i)})\\log(1 - y^{(i)})\\right)$$\n",
        "\n",
        "   where **$n_{\\text{obs}}$ is the number of data-points**, ${t}^{(i)}$ is the actual value, and $y^{(i)}$ is the predicted value for the data-point $i$.\n",
        "\n",
        "- For multi-class classification problems, the Cross Entropy Loss can be deifined as follows:\n",
        "\n",
        "$$E= - \\frac{1}{N_{\\text{obs}}} \\sum_{i=1}^{n_{\\text{obs}}} \\sum_{j=1}^{m} t_{j}^{(i)} \\log(y_j^{(i)})$$\n",
        "\n",
        "  where **$n_{\\text{obs}}$ is the number of data-points**, $t_{j}^{(i)}$ is the actual value for class j for the data-point $i$, and $y_j^{(i)}$ is the predicted value.\n",
        "\n",
        "Now we have to find the gradient for each weight and bias for each data-point. Let's assume a binary classification problem. Before we calculate the gradient let's find the derivatives of the activation function (Sigmoid function) and the error function (Binary Cross Entropy Loss).\n",
        "\n",
        "\n",
        "The first derivative of the Sigmoid function [$\\sigma(x)$]:\n",
        "\n",
        "$$\\frac{d \\sigma(z)}{dz} = \\sigma(z) \\cdot (1 - \\sigma(z))$$\n",
        "\n",
        "\n",
        "The first derivative of the Binary Cross Entropy Loss [$ -(t\\log(y) + (1 - t)\\log(1 - y)$]:\n",
        "\n",
        "$$\n",
        "\\frac{d E}{dy} = - \\bigg( \\frac{t} {y} - \\frac{(1 - t)}{(1 - y)} \\bigg)\n",
        "$$\n",
        "\n",
        "\n",
        "## For the weights in the output layer:\n",
        "     \n",
        "$$\\frac{\\partial E}{\\partial w_i^{(\\text{out})}} = \\frac{\\partial E}{\\partial y} \\frac{\\partial y}{\\partial z^{(\\text{out})}} \\frac{\\partial z^{(\\text{out})}}{\\partial w_{i}^{(\\text{out})}} \\\\\n",
        "\\quad = - \\Bigg[\\bigg( \\frac{t} {y} - \\frac{(1 - t)}{(1 - y)} \\bigg) \\Bigg] \\Bigg[\\bigg(\\frac{1}{1 + e^{-z_i^{(\\text{out})}}} \\bigg) \\bigg(1- \\bigg(\\frac{1}{1 + e^{-z^{(\\text{out})}}} \\bigg) \\bigg) \\Bigg] a_{i}^{(\\text{hidden})}\n",
        "$$\n",
        "\n",
        "## For the biases in the output layer:\n",
        "     \n",
        "$$\\frac{\\partial E}{\\partial \\theta^{(\\text{out})}} = \\frac{\\partial E}{\\partial y} \\frac{\\partial y}{\\partial z^{(\\text{out})}} \\frac{\\partial z^{(\\text{out})}}{\\partial \\theta^{(\\text{out})}} \\\\\n",
        "\\quad = - \\Bigg[\\bigg( \\frac{t} {y} - \\frac{(1 - t)}{(1 - y)} \\bigg) \\Bigg] \\Bigg[\\bigg(\\frac{1}{1 + e^{-z_i^{(\\text{out})}}} \\bigg) \\bigg(1- \\bigg(\\frac{1}{1 + e^{-z^{(\\text{out})}}} \\bigg) \\bigg) \\Bigg] \\cdot 1\n",
        "$$\n",
        "\n",
        "## For the weights in the hidden layer:\n",
        "     \n",
        "$$\n",
        "\\frac{\\partial E}{\\partial w_{ij}^{(\\text{hidden})}} \\\\\n",
        "= \\frac{\\partial E}{\\partial y} \\frac{\\partial y}{\\partial z^{(\\text{out})}} \\frac{\\partial z^{(\\text{out})}}{\\partial a_{i}^{(\\text{hidden})}} \\frac{\\partial a_i^{(\\text{hidden})}}{\\partial z_{i}^{(\\text{hidden})}} \\frac{\\partial z_i^{(\\text{hidden})}}{\\partial w_{ij}^{(\\text{hidden})}} \\\\\n",
        "\\quad = \\frac{\\partial E}{\\partial z^{(\\text{out})}} w_{ij}^{(\\text{out})} x_{j}\n",
        "$$\n",
        "\n",
        "\n",
        "## For the biases in the hidden layer:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial E}{\\partial \\theta_i^{(\\text{hidden})}} = \\frac{\\partial E}{\\partial z_i^{(\\text{hidden})}} \\frac{\\partial z_i^{(\\text{hidden})}}{\\partial \\theta_i^{(\\text{hidden})}} \\\\\n",
        "= \\frac{\\partial E}{\\partial y} \\frac{\\partial y}{\\partial z^{(\\text{out})}} \\frac{\\partial z^{(\\text{out})}}{\\partial z_{i}^{(\\text{hidden})}} \\frac{\\partial z_i^{(\\text{hidden})}}{\\partial \\theta_{i}^{(\\text{hidden})}} \\\\\n",
        "\\quad = \\frac{\\partial E} {\\partial z^{(\\text{out})}} w_{ij}^{(\\text{out})} \\cdot 1\n",
        "$$\n",
        "\n",
        "\n",
        "Where:\n",
        "- $E$ is the error function.\n",
        "- $\\alpha$ is the learning rate.\n",
        "- $w_{ij}^{(\\text{hidden})}$ and $w_i^{(\\text{out})}$ are the weights of the hidden and output layers, respectively.\n",
        "- $\\theta_i^{(\\text{hidden})}$ and $\\theta^{(\\text{out})}$ are the biases of the hidden and output layers, respectively.\n",
        "\n",
        "3. **Iterations:**\n",
        "\n",
        "   Update the weights and biases using an optimization technique such as gradient descent:\n",
        "     \n",
        "     $$w_{\\text{new}} = w_{\\text{old}} - \\alpha \\frac{\\partial E}{\\partial w}$$\n",
        "     $$\\theta_{\\text{new}} = \\theta_{\\text{old}} - \\alpha \\frac{\\partial E}{\\partial \\theta}$$\n",
        "\n",
        "\n",
        "## Vectorization for Performance\n",
        " We can express the forward pass and the backward pass using matrix notation.\n",
        "\n",
        "1. **Forward Pass:**\n",
        "\n",
        "Let's denote the weight matrices and bias vectors as follows:\n",
        "\n",
        "- Input vector: ${x}^{(\\text{in})} = [x_1^{(\\text{in})}, x_2^{(\\text{in})}, x_3^{(\\text{in})}, ..., x_{n_{\\text{in}}}^{(\\text{in})}]$.\n",
        "- Weight column vector for the hidden layer $i$: $w_i^{(\\text{hidden})} = [w_{i1}^{(\\text{hidden})}, w_{i2}^{(\\text{hidden})}, w_{i3}^{(\\text{hidden})}, ...,w_{i{n_{\\text{in}}}}^{(\\text{hidden})}]^T$\n",
        "- Weight matrix for the hidden layer: $W^{(\\text{hidden})} = [w_{1}^{(\\text{hidden})}, w_{2}^{(\\text{hidden})}, w_{3}^{(\\text{hidden})}, ..., w_{n_{\\text{hidden}}}^{(\\text{hidden})}]$.\n",
        "- Bias vector for the hidden layer: $\\theta^{(\\text{hidden})} = [\\theta_i^{(\\text{hidden})}]$.\n",
        "- Weight vector for the single node output layer: $w^{(\\text{out})} = [w_i^{(\\text{out})}]$.\n",
        "- Bias scalar for the single node output layer: $\\theta^{(\\text{out})}$.\n",
        "\n",
        "\n",
        "The forward pass for the hidden layer can be represented as:\n",
        "   \n",
        "   $$z^{(\\text{hidden})} = W^{(\\text{hidden})} \\cdot x + \\theta^{(\\text{hidden})}$$\n",
        "   \n",
        "   Then applying the activation function, we get:\n",
        "   \n",
        "   $$x^{(\\text{hidden})} = f(z^{(\\text{hidden})})$$\n",
        "   \n",
        "   The forward pass for the output layer is:\n",
        "   \n",
        "   $$y = w^{(\\text{out})} \\cdot x^{(\\text{hidden})} + \\theta^{(\\text{out})}$$\n",
        "\n",
        "2. **Backward Pass:**\n",
        "\n",
        "   The gradients for the weights and biases in the backward pass can be represented as:\n",
        "   \n",
        "   - For the weights in the output layer:\n",
        "     \n",
        "     $$\\frac{\\partial E}{\\partial w^{(\\text{out})}} = \\frac{\\partial E}{\\partial y} \\cdot \\frac{\\partial y}{\\partial z^{(\\text{out})}} \\cdot \\frac{\\partial z^{(\\text{out})}}{\\partial w^{(\\text{out})}}$$\n",
        "     \n",
        "   - For the biases in the output layer:\n",
        "     \n",
        "     $$\\frac{\\partial E}{\\partial \\theta^{(\\text{out})}} = \\frac{\\partial E}{\\partial y} \\cdot \\frac{\\partial y}{\\partial z^{(\\text{out})}} \\cdot \\frac{\\partial z^{(\\text{out})}}{\\partial \\theta^{(\\text{out})}}$$\n",
        "   \n",
        "   - For the weights in the hidden layer:\n",
        "     \n",
        "     $$\\frac{\\partial E}{\\partial w^{(\\text{hidden})}} = \\frac{\\partial E}{\\partial z^{(\\text{hidden})}} \\cdot \\frac{\\partial z^{(\\text{hidden})}}{\\partial w^{(\\text{hidden})}}$$\n",
        "   \n",
        "   - For the biases in the hidden layer:\n",
        "     \n",
        "     $$\\frac{\\partial E}{\\partial \\theta^{(\\text{hidden})}} = \\frac{\\partial E}{\\partial z^{(\\text{hidden})}} \\cdot \\frac{\\partial z^{(\\text{hidden})}}{\\partial\\theta^{(\\text{hidden})}}$$\n",
        "\n",
        "3. **Iterations:**\n",
        "\n",
        "   Update the weights and biases using the gradients and the learning rate ($\\alpha$):\n",
        "   \n",
        "   $$w^{(\\text{hidden})}_{\\text{new}} = w^{(\\text{hidden})}_{\\text{old}} - \\alpha \\frac{\\partial E}{\\partial w^{(\\text{hidden})}}$$\n",
        "   \n",
        "   $$\\theta^{(\\text{hidden})}_{\\text{new}} = \\theta^{(\\text{hidden})}_{\\text{old}} - \\alpha \\frac{\\partial E}{\\partial \\theta^{(\\text{hidden})}}$$\n",
        "   \n",
        "   $$w^{(\\text{out})}_{\\text{new}} = w^{(\\text{out})}_{\\text{old}} - \\alpha \\frac{\\partial E}{\\partial w^{(\\text{out})}}$$\n",
        "   \n",
        "   $$\\theta^{(\\text{out})}_{\\text{new}} = \\theta^{(\\text{out})}_{\\text{old}} - \\alpha \\frac{\\partial E}{\\partial \\theta^{(\\text{out})}}$$\n",
        "\n",
        "Here, $z^{(\\text{hidden})}$ and $x^{(\\text{hidden})}$ are vectors of the hidden layer's weighted sums and its activations, respectively. The function $f$ is the activation function applied element-wise. The error function $E$ depends on the specific problem and can be defined accordingly."
      ],
      "metadata": {
        "id": "ws6aItKdtAI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate independent input data\n",
        "np.random.seed(1)\n",
        "feature1 = np.random.rand(1000)\n",
        "feature2 = np.random.rand(1000)\n",
        "feature3 = np.random.rand(1000)\n",
        "X = np.column_stack((feature1, feature2, feature3))\n",
        "\n",
        "# Generate correlated output data\n",
        "y = (1 / (1 + np.exp(-(0.3 * feature1 + 0.5 * feature2 - 0.2 * feature3 + np.random.normal(0, 0.1, 1000)))) > 0.5).astype(int)\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of the sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "def binary_cross_entropy_derivative(y, t):\n",
        "    \"\"\"\n",
        "    Compute the derivative of the Binary Cross Entropy Loss with respect to y.\n",
        "\n",
        "    Args:\n",
        "    y (numpy.ndarray): Predicted output.\n",
        "    t (numpy.ndarray): True labels.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Derivative of the Binary Cross Entropy Loss.\n",
        "    \"\"\"\n",
        "    return -((t / y) - ((1 - t) / (1 - y)))\n",
        "\n",
        "# Initialize weights and biases\n",
        "input_dim, hidden_dim, output_dim = 3, 5, 1\n",
        "weights_input_hidden = np.random.rand(input_dim, hidden_dim)\n",
        "bias_hidden = np.random.rand(1, hidden_dim)\n",
        "weights_hidden_output = np.random.rand(hidden_dim, output_dim)\n",
        "bias_output = np.random.rand(1, output_dim)\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate, epochs = 0.1, 1000\n",
        "epoch_list, error_list = [], []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    hidden_layer_input = np.dot(X, weights_input_hidden) + bias_hidden # Calculate input to the hidden layer\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input) # Apply activation function to the hidden layer\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output # Calculate input to the output layer\n",
        "    predicted_output = sigmoid(output_layer_input) # Apply activation function to the output layer\n",
        "\n",
        "    # Backpropagation\n",
        "    error = y - predicted_output # Compute the error\n",
        "    d_predicted_output = error * sigmoid_derivative(predicted_output) # Compute the derivative of the error with respect to the predicted output\n",
        "    error_hidden_layer = d_predicted_output.dot(weights_hidden_output.T) # Compute the error in the hidden layer\n",
        "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output) # Compute the derivative of the error with respect to the hidden layer\n",
        "\n",
        "    # Update weights and biases\n",
        "    weights_hidden_output += hidden_layer_output.T.dot(d_predicted_output) * learning_rate # Update the weights between the hidden and output layers\n",
        "    bias_output += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate # Update the bias of the output layer\n",
        "    weights_input_hidden += X.T.dot(d_hidden_layer) * learning_rate # Update the weights between the input and hidden layers\n",
        "    bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate # Update the bias of the hidden layer\n",
        "\n",
        "    # Record and print the error at every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        epoch_list.append(epoch)\n",
        "        error_list.append(np.mean(np.abs(error)))\n",
        "\n",
        "# Final predictions\n",
        "threshold = 0.5\n",
        "predicted_classes = (predicted_output > threshold).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y, predicted_classes)\n",
        "\n",
        "# Calculate the overall accuracy\n",
        "overall_accuracy = np.trace(cm) / np.sum(cm)\n",
        "\n",
        "# Print the confusion matrix and overall accuracy\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(f\"Overall Accuracy: {overall_accuracy}\")\n",
        "\n",
        "# Plotting the error\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epoch_list, error_list, marker='o', linestyle='--', color='b', label='Error')\n",
        "plt.title('Error vs Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "_diW48VGa4zy",
        "outputId": "6290bf5c-2112-42be-c9cc-f1b9c3f40373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 43  23]\n",
            " [ 30 904]]\n",
            "Overall Accuracy: 0.947\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate independent input data\n",
        "np.random.seed(1)\n",
        "feature1 = np.random.rand(1000)\n",
        "feature2 = np.random.rand(1000)\n",
        "feature3 = np.random.rand(1000)\n",
        "X = np.column_stack((feature1, feature2, feature3))\n",
        "\n",
        "# Generate correlated output data\n",
        "y = (1 / (1 + np.exp(-(0.3 * feature1 + 0.5 * feature2 - 0.2 * feature3 + np.random.normal(0, 0.1, 1000)))) > 0.5).astype(int)\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of the sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "def bce_derivative(y, t):\n",
        "    \"\"\"\n",
        "    Compute the derivative of the Binary Cross Entropy Loss with respect to y.\n",
        "\n",
        "    Args:\n",
        "    y (numpy.ndarray): Predicted output.\n",
        "    t (numpy.ndarray): True labels.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Derivative of the Binary Cross Entropy Loss.\n",
        "    \"\"\"\n",
        "    return -((t / y) - ((1 - t) / (1 - y)))\n",
        "\n",
        "# Initialize weights and biases\n",
        "input_dim, hidden_dim, output_dim = 3, 5, 1\n",
        "weights_input_hidden = np.random.rand(input_dim, hidden_dim)\n",
        "bias_hidden = np.random.rand(1, hidden_dim)\n",
        "weights_hidden_output = np.random.rand(hidden_dim, output_dim)\n",
        "bias_output = np.random.rand(1, output_dim)\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate, epochs = 0.1, 1000\n",
        "epoch_list, error_list = [], []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    hidden_layer_input = np.dot(X, weights_input_hidden) + bias_hidden # Calculate input to the hidden layer\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input) # Apply activation function to the hidden layer\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output # Calculate input to the output layer\n",
        "    predicted_output = sigmoid(output_layer_input) # Apply activation function to the output layer\n",
        "\n",
        "    # Backpropagation\n",
        "    error = y - predicted_output # Compute the error\n",
        "    d_predicted_output = bce_derivative(predicted_output) # Compute the derivative of the error with respect to the predicted output\n",
        "    d_output_layer_input = bce_derivative(predicted_output) * sigmoid_derivative(hidden_layer_input) # Compute the derivative of the error with respect to the output layer inputs\n",
        "   # error_hidden_layer = d_predicted_output.dot(weights_hidden_output.T) # Compute the error in the hidden layer\n",
        "\n",
        "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output) # Compute the derivative of the error with respect to the hidden layer\n",
        "\n",
        "    # Update weights and biases\n",
        "    weights_hidden_output += hidden_layer_output.T.dot(d_predicted_output) * learning_rate # Update the weights between the hidden and output layers\n",
        "    bias_output += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate # Update the bias of the output layer\n",
        "    weights_input_hidden += X.T.dot(d_hidden_layer) * learning_rate # Update the weights between the input and hidden layers\n",
        "    bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate # Update the bias of the hidden layer\n",
        "\n",
        "    # Record and print the error at every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        epoch_list.append(epoch)\n",
        "        error_list.append(np.mean(np.abs(error)))\n",
        "\n",
        "# Final predictions\n",
        "threshold = 0.5\n",
        "predicted_classes = (predicted_output > threshold).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y, predicted_classes)\n",
        "\n",
        "# Calculate the overall accuracy\n",
        "overall_accuracy = np.trace(cm) / np.sum(cm)\n",
        "\n",
        "# Print the confusion matrix and overall accuracy\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(f\"Overall Accuracy: {overall_accuracy}\")\n",
        "\n",
        "# Plotting the error\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epoch_list, error_list, marker='o', linestyle='--', color='b', label='Error')\n",
        "plt.title('Error vs Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "fd1ca14f-cfb2-4398-a8c0-261f7a3f34c8",
        "id": "OQgRyFGK3eSl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 43  23]\n",
            " [ 30 904]]\n",
            "Overall Accuracy: 0.947\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![graphviz.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "irLvB3-ilULp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Backpropogation in Matrix Form for a Single Data-Point\n",
        "The neural network architecture we will work with consists of 3 nodes in the input layer, 4 nodes in the hidden layer, and 1 node in the output layer. Our specific goal is to address a binary classification problem, where the output is of the 'yes' or 'no' type.\n",
        "\n",
        "For this purpose, we will utilize the sigmoid activation function, known for its ability to map inputs to a range between 0 and 1, thus facilitating the binary classification. Additionally, the Binary Cross Entropy (BCE) error function will be employed to assess the disparity between predicted and actual values.\n",
        "\n",
        "Initially, we will focus on a single data point and gradually extend our approach to handle datasets. To begin, we will construct a vector that represents the input values, reflecting the features of the data point.\n",
        "\n",
        "## Input Vector\n",
        "Let $x$ be the input vector with three features, $x = [x_1, x_2, x_3]^T$. Each of the elements \\(x_1\\), \\(x_2\\), and \\(x_3\\) represents the values of the features in the input layer.\n",
        "\n",
        "\n",
        "$$ x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} $$\n",
        "\n",
        "This represents the input vector for one data point with three features.\n",
        "\n",
        "## Weight Matrix for the Hidden Layer\n",
        "Let's denote the weight matrix as $W_{\\text{hidden}}$, which connects the input layer to the hidden layer. The bias terms are incorporated into the weight matrix as additional elements in each row.\n",
        "\n",
        "The dimensions of $W_{\\text{hidden}}$ will be $4 \\times 4$ (4 nodes in the hidden layer and 3 nodes in the input layer, including the bias term).\n",
        "\n",
        "The weight matrix $W_{\\text{hidden}}$ can be represented as:\n",
        "\n",
        "$$\n",
        "W_{\\text{hidden}} =\n",
        "\\begin{bmatrix}\n",
        "w_{11} & w_{12} & w_{13} & \\theta_1 \\\\\n",
        "w_{21} & w_{22} & w_{23} & \\theta_2 \\\\\n",
        "w_{31} & w_{32} & w_{33} & \\theta_3 \\\\\n",
        "w_{41} & w_{42} & w_{43} & \\theta_4 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "where $w_{ij}$ denotes the weight connecting the $i$ th node in the hidden layer to the $j$ th node in the input layer, an $\\theta_i$ represents the bias term for the $i$ th node in the hidden layer.\n",
        "\n",
        "## Input Vector for the Hidden Layer\n",
        "\n",
        "Given the input vector \\(x\\) as:\n",
        "\n",
        "$$ x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} $4\n",
        "\n",
        "with the additional element 1 appended at the end, the augmented vector becomes:\n",
        "\n",
        "$$ x' = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ 1 \\end{bmatrix} $4\n",
        "\n",
        "Then the input vector for the hidden layer, $z_{\\text{hidden}}$, is computed as:\n",
        "\n",
        "$$ z_{\\text{hidden}} = W_{\\text{hidden}} \\cdot x' $$\n",
        "\n",
        "where $z_{\\text{hidden}}$ will be a 4x1 vector representing the input to the hidden layer.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "w_{11} & w_{12} & w_{13} & \\theta_1 \\\\\n",
        "w_{21} & w_{22} & w_{23} & \\theta_2 \\\\\n",
        "w_{31} & w_{32} & w_{33} & \\theta_3 \\\\\n",
        "w_{41} & w_{42} & w_{43} & \\theta_4 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "x_3 \\\\\n",
        "1\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "w_{11}x_1 + w_{12}x_2 + w_{13}x_3 + \\theta_1 \\\\\n",
        "w_{21}x_1 + w_{22}x_2 + w_{23}x_3 + \\theta_2 \\\\\n",
        "w_{31}x_1 + w_{32}x_2 + w_{33}x_3 + \\theta_3 \\\\\n",
        "w_{41}x_1 + w_{42}x_2 + w_{43}x_3 + \\theta_4 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "## Activation Vector of the Hidden Layer\n",
        "The activation vector for the hidden layer is obtained by applying the activation function (in this case, the sigmoid function) to the elements of the input matrix $Z_{\\text{hidden}}$. Let's denote the activation vector for the hidden layer as $a_{\\text{hidden}}$.\n",
        "\n",
        "Taking the $z_{\\text{hidden}}$ as the input matrix for the hidden layer:\n",
        "\n",
        "$$\n",
        "Z_{\\text{hidden}} = \\begin{bmatrix}\n",
        "z_1 \\\\\n",
        "z_2 \\\\\n",
        "z_3 \\\\\n",
        "z_4\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "then the activation vector for the hidden layer, $a_{\\text{hidden}}$, is computed as:\n",
        "\n",
        "$$a_{\\text{hidden}} = \\begin{bmatrix}\n",
        "\\sigma(z_1) \\\\\n",
        "\\sigma(z_2) \\\\\n",
        "\\sigma(z_3) \\\\\n",
        "\\sigma(z_4)\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "where $\\sigma$ is the sigmoid activation function.\n",
        "\n",
        "## Weight Vector for the Output Layer (Single Node)\n",
        "\n",
        "The weight vector for the output layer, considering there is a single node, can be denoted as $w_{\\text{output}}$. This weight vector will connect the hidden layer to the output layer. The dimension of $w_{\\text{output}}$ will be $4 \\times 1$ (4 nodes in the hidden layer).\n",
        "\n",
        "The weight vector $w_{\\text{output}}$ can be represented as:\n",
        "\n",
        "$$ w_{\\text{output}} = \\begin{bmatrix}\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "w_3 \\\\\n",
        "w_4 \\\\\n",
        "\\end{bmatrix} $$\n",
        "\n",
        "where $w_1$, $w_2$, $w_3$, and $w_4$ represent the weights connecting the nodes in the hidden layer to the single node in the output layer.\n",
        "\n",
        "## Input Vector for the Output Layer\n",
        "Let's define the activation vector $a_{\\text{hidden}}$ first as:\n",
        "\n",
        "$$ a_{\\text{hidden}} = \\begin{bmatrix} a_1 \\\\ a_2 \\\\ a_3 \\\\ a_4 \\end{bmatrix} $$\n",
        "\n",
        "Then, the input scalar for the output layer can be computed as the dot product of $w_{\\text{output}}^T$ and $a_{\\text{hidden}}$, represented as:\n",
        "\n",
        "$$\n",
        "w_{\\text{output}}^T \\cdot a_{\\text{hidden}} =\n",
        "\\begin{bmatrix} w_1 & w_2 & w_3 & w_4 \\end{bmatrix}\n",
        "\\begin{bmatrix} a_1 \\\\ a_2 \\\\ a_3 \\\\ a_4 \\end{bmatrix}\n",
        "= w_1a_1 + w_2a_2 + w_3a_3 + w_4a_4\n",
        "$$\n",
        "\n",
        "## Scalar Output of the Output Layer\n",
        "The output scalar of the output layer is determined by applying the activation function, in this case, the sigmoid function, to the input scalar of the output layer. Let's denote the input scalar as $a_{\\text{out}}$  and the output scalar as $y$.\n",
        "\n",
        "$$\n",
        "y = \\sigma(a_{\\text{out}})\n",
        "$$\n",
        "\n",
        "where \\(\\sigma\\) is the sigmoid activation function, and the \"Input Scalar of the Output Layer\" represents the linear combination obtained before applying the activation function.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "86pxFKX6YXoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initializing values\n",
        "x1, x2, x3 = 0.5, 0.3, 0.2\n",
        "w11, w12, w13, theta1 = 0.1, 0.2, 0.3, 0.4\n",
        "w21, w22, w23, theta2 = 0.2, 0.3, 0.4, 0.5\n",
        "w31, w32, w33, theta3 = 0.3, 0.4, 0.5, 0.6\n",
        "w41, w42, w43, theta4 = 0.4, 0.5, 0.6, 0.7\n",
        "w1, w2, w3, w4 = 0.5, 0.6, 0.7, 0.8\n",
        "\n",
        "# Input Vector\n",
        "x = np.array([[x1], [x2], [x3]])\n",
        "\n",
        "# Weight Matrix for the Hidden Layer\n",
        "W_hidden = np.array([[w11, w12, w13, theta1],\n",
        "                     [w21, w22, w23, theta2],\n",
        "                     [w31, w32, w33, theta3],\n",
        "                     [w41, w42, w43, theta4]])\n",
        "\n",
        "# Input Vector for the Hidden Layer\n",
        "x_augmented = np.append(x, [[1]], axis=0)\n",
        "z_hidden = np.dot(W_hidden, x_augmented)\n",
        "\n",
        "# Activation Vector of the Hidden Layer\n",
        "a_hidden = 1 / (1 + np.exp(-z_hidden))\n",
        "\n",
        "# Weight Vector for the Output Layer (Single Node)\n",
        "w_output = np.array([[w1], [w2], [w3], [w4]])\n",
        "\n",
        "# Input Vector for the Output Layer\n",
        "a_out = np.dot(w_output.T, a_hidden)\n",
        "\n",
        "# Scalar Output of the Output Layer\n",
        "y = 1 / (1 + np.exp(-a_out))\n",
        "\n",
        "# Printing the relevant vectors, matrices, and scalar\n",
        "print(\"Input Vector: \\n\", x)\n",
        "print(\"Weight Matrix for the Hidden Layer: \\n\", W_hidden)\n",
        "print(\"Input Vector for the Hidden Layer: \\n\", x_augmented)\n",
        "print(\"Activation Vector of the Hidden Layer: \\n\", a_hidden)\n",
        "print(\"Weight Vector for the Output Layer: \\n\", w_output)\n",
        "print(\"Input Scalar for the Output Layer: \\n\", a_out)\n",
        "print(\"Scalar Output of the Output Layer: \\n\", y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhhLmxTmt5RX",
        "outputId": "c1b4e026-0259-4cda-a1a2-7b88c0007784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Vector: \n",
            " [[0.5]\n",
            " [0.3]\n",
            " [0.2]]\n",
            "Weight Matrix for the Hidden Layer: \n",
            " [[0.1 0.2 0.3 0.4]\n",
            " [0.2 0.3 0.4 0.5]\n",
            " [0.3 0.4 0.5 0.6]\n",
            " [0.4 0.5 0.6 0.7]]\n",
            "Input Vector for the Hidden Layer: \n",
            " [[0.5]\n",
            " [0.3]\n",
            " [0.2]\n",
            " [1. ]]\n",
            "Activation Vector of the Hidden Layer: \n",
            " [[0.63876318]\n",
            " [0.68352089]\n",
            " [0.7251195 ]\n",
            " [0.76314502]]\n",
            "Weight Vector for the Output Layer: \n",
            " [[0.5]\n",
            " [0.6]\n",
            " [0.7]\n",
            " [0.8]]\n",
            "Input Scalar for the Output Layer: \n",
            " [[1.84759378]]\n",
            "Scalar Output of the Output Layer: \n",
            " [[0.86384434]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropogation\n",
        "\n",
        "## Calculate the Error for the Output Layer (Single Node)\n",
        "\n",
        "To compute the error scalar using the Binary Cross Entropy (BCE) function, we need the output scalar of the output layer (single node), denoted as $y$, and the observed true value scalar, denoted as $t$.\n",
        "\n",
        "The BCE function is given by:\n",
        "\n",
        "$$ E(y, t) = -[t \\cdot \\log(y) + (1 - t) \\cdot \\log(1 - y)] $$\n",
        "\n",
        "where $t$ is the observed true value and $y$ is the output scalar of the output layer.\n",
        "\n",
        "## Caclualte the Gradient for the Weights of Output Layer\n",
        "Partial derivative scalar of $E$ with respect to $y$:\n",
        "\n",
        "$$ \\frac{\\partial E}{\\partial y} = -\\left[\\frac{t}{y} - \\frac{1-t}{1-y}\\right] $$\n",
        "\n",
        "Partial derivative scalar of $y$ with respect to the input for the output layer, denoted as $z_{\\text{out}}$:\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial z_{\\text{out}}} =  \\sigma(z) \\cdot \\sigma(1 - y)$$\n",
        "\n",
        "\n",
        "We can incorporate the bias term $\\theta$ into the weight vector $w_{\\text{output}}$ as an additional element. Then the calculation of the gradient for the output layer weights can be represented as the **partial derivative scalar of $E$ with respect to $y$** multiplied by the **partial derivative scalar of $y$ with respect to $z_{\\text{out}}$, multiplied by the activation vector $a_{\\text{hidden}}$ (from the chain rule).\n",
        "\n",
        "Let the weight vector of the output layer be denoted as $w_{\\text{output}}$:\n",
        "\n",
        "$$\n",
        "w_{\\text{output}} =\n",
        "\\begin{bmatrix}\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "w_3 \\\\\n",
        "w_4 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Let the modified weight vector for the output layer be denoted as $w'_{\\text{output}}$:\n",
        "\n",
        "$$\n",
        "w'_{\\text{output}} =\n",
        "\\begin{bmatrix}\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "w_3 \\\\\n",
        "w_4 \\\\\n",
        "\\theta \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Then, the gradient for the output layer weights can be represented as:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial E}{\\partial w'_{\\text{output}}} =\n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial E}{\\partial w_1} \\\\\n",
        "\\frac{\\partial E}{\\partial w_2} \\\\\n",
        "\\frac{\\partial E}{\\partial w_3} \\\\\n",
        "\\frac{\\partial E}{\\partial w_4} \\\\\n",
        "\\frac{\\partial E}{\\partial \\theta} \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "where each element of the gradient vector is computed using the chain rule, resulting in:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial E}{\\partial w'_i} = \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times \\frac{\\partial z_{\\text{out}}}{\\partial w'_i}  =  -\\left[\\frac{t}{y} - \\frac{1-t}{1-y}\\right] \\times \\sigma(z_{\\text{out}}) \\times \\sigma(1 - y) \\times a_{i, \\text{hidden}}\n",
        "$$\n",
        "\n",
        "where $i = 1,2,3,4$ denote the elements of the weight vector $w'_{\\text{output}}$.\n",
        "\n",
        "Let's dentoe the activation vector for the hidden layer, $a_{\\text{hidden}}$, is a column vector:\n",
        "\n",
        "$$a_{\\text{hidden}} = \\begin{bmatrix} a_1 \\\\ a_2 \\\\ a_3 \\\\ a_4 \\end{bmatrix} $$\n",
        "\n",
        "\n",
        "We can now express the gradient vector $\\frac{\\partial E}{\\partial w'} $ as follows:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial E}{\\partial w'} = \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times \\frac{\\partial z_{\\text{out}}}{\\partial w'_i}  =  -\\left[\\frac{t}{y} - \\frac{1-t}{1-y}\\right] \\times \\sigma(z_{\\text{out}}) \\times \\sigma(1 - y) \\cdot a_{\\text{hidden}}\n",
        "$$\n",
        "\n",
        "\n",
        "## Calculate the Gradient for the Weights of the Hidden Layer\n",
        "\n",
        "The weight matrix for the hidden layer, including the $\\theta $terms, is denoted as $W'_{\\text{hidden}}$:\n",
        "\n",
        "$$\n",
        "W'_{\\text{hidden}} =\n",
        "\\begin{bmatrix}\n",
        "w_{11} & w_{12} & w_{13} & \\theta_1 \\\\\n",
        "w_{21} & w_{22} & w_{23} & \\theta_2 \\\\\n",
        "w_{31} & w_{32} & w_{33} & \\theta_3 \\\\\n",
        "w_{41} & w_{42} & w_{43} & \\theta_4 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "where $i = 1,2,3,4$ denoted the nodes of hidden layer and  $j=1,2,3$ dentoted the input layer nodes (input layer values).\n",
        "\n",
        "The partial derivative of error $ E $ with respect to each weight can be calculated using the chain rule. For each weight $ w_{ij} $ and the bias term \\$theta_i $, the derivatives are as follows:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial E}{\\partial w_{ij}} = \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times \\frac{\\partial z_{\\text{out}}}{\\partial a_{i, \\text{hidden}}} \\times \\frac{\\partial a_{i, \\text{hidden}}}{\\partial z_{i, \\text{hidden}}} \\times \\frac{\\partial z_{i, \\text{hidden}}}{\\partial w_{ij}} \\\\\n",
        "= \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times w_{i, \\text{out}} \\times \\sigma(z_{i, \\text{hidden}}) \\times \\sigma(1 - z_{i, \\text{hidden}}) \\times x_{j, \\text{input}}\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "\\frac{\\partial E}{\\partial \\theta_i} = \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times \\frac{\\partial z_{\\text{out}}}{\\partial a_{i, \\text{hidden}}} \\times \\frac{\\partial a_{i, \\text{hidden}}}{\\partial z_{i, \\text{hidden}}} \\times \\frac{\\partial z_{i, \\text{hidden}}}{\\partial \\theta_i} \\\\\n",
        "= \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times w_{i, \\text{out}} \\times \\sigma(z_{i, \\text{hidden}}) \\times \\sigma(1 - z_{i, \\text{hidden}}) \\times 1\n",
        "$$\n",
        "\n",
        "\n",
        "The derivative vector $ \\frac{\\partial z_{\\text{hidden}}}{\\partial W'_{\\text{hidden}}} $ can be represented as:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z_{\\text{hidden}}}{\\partial W'_{\\text{hidden}}} = x'_{\\text{input}}\n",
        "$$\n",
        "\n",
        "where $ x'_{\\text{input}} $ is the input layer vector, augmented with the bias term.\n",
        "\n",
        "$$ x'_{\\text{input}} = \\begin{bmatrix} x_{1} & x_{2} & x_{3} & 1 \\end{bmatrix}$$\n",
        "\n",
        "and\n",
        "\n",
        "$$ z_{\\text{hidden}} = \\begin{bmatrix} z_{1} & z_{2} & z_{3} & z_{4} \\end{bmatrix}$$\n",
        "\n",
        "The derivative vector $ \\frac{\\partial z_{\\text{out}}}{\\partial z_{\\text{hidden}}} $ can be represented element wise multiplication:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z_{\\text{out}}}{\\partial z_{\\text{hidden}}} = \\frac{\\partial z_{\\text{out}}}{\\partial a_{\\text{hidden}}} \\odot \\frac{\\partial a_{\\text{hidden}}}{\\partial z_{\\text{hidden}}} = w_{\\text{output}} \\odot \\sigma(z_{\\text{hidden}})\n",
        "$$\n",
        "\n",
        "\n",
        "We can now express the gradient vector $\\frac{\\partial E}{\\partial W'_{\\text{hidden}}}$ as follows:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial E}{\\partial W'_{\\text{hidden}}} = \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times \\frac{\\partial z_{\\text{out}}}{\\partial a_{i, \\text{hidden}}} \\times \\frac{\\partial a_{i, \\text{hidden}}}{\\partial z_{i, \\text{hidden}}} \\times \\frac{\\partial z_{i, \\text{hidden}}}{\\partial w_{ij}} \\\\\n",
        "= = \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times w_{\\text{output}} \\odot \\sigma(z_{\\text{hidden}}) \\otimes x'_{\\text{input}}\n",
        "$$\n",
        "\n",
        "## Update Weights (including $\\theta$)\n",
        "\n",
        "The weight update equations for the output layer and the hidden layer, incorporating the gradient information derived, can be represented as follows:\n",
        "\n",
        "### Output Layer Weight Update\n",
        "For the weight vector of the output layer $w'_{\\text{output}}$, the weight update equation can be expressed as:\n",
        "\n",
        "$$\n",
        "w'_{\\text{output}}(n+1) = w'_{\\text{output}}(n) - \\alpha \\cdot \\frac{\\partial E}{\\partial w'_{\\text{output}}}\n",
        "$$\n",
        "\n",
        "where $w'_{\\text{output}}(n+1)$ is the updated weight vector, $w'_{\\text{output}}(n)$ is the current weight vector, $\\alpha$ is the learning rate, and $\\frac{\\partial E}{\\partial w'_{\\text{output}}}$ is the gradient vector for the output layer weights.\n",
        "\n",
        "### Hidden Layer Weight Update\n",
        "For the weight matrix of the hidden layer $W'_{\\text{hidden}}$, the weight update equation can be expressed as:\n",
        "\n",
        "$$\n",
        "W'_{\\text{hidden}}(n+1) = W'_{\\text{hidden}}(n) - \\alpha \\cdot \\frac{\\partial E}{\\partial W'_{\\text{hidden}}}\n",
        "$$\n",
        "\n",
        "where $W'_{\\text{hidden}}(n+1)$ is the updated weight matrix, $W'_{\\text{hidden}}(n)$ is the current weight matrix, $\\alpha $ is the learning rate, and $\\frac{\\partial E}{\\partial W'_{\\text{hidden}}}$ is the gradient matrix for the hidden layer weights.\n"
      ],
      "metadata": {
        "id": "lH1DsO2vx9H2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Notation of Neural Nets for a Dataset\n",
        "\n",
        "$ \\text{Let } X \\text{ be the input matrix with five data points and three features, where each data point is represented as a row}$:\n",
        "\n",
        "$ X = \\begin{bmatrix}\n",
        "x_{11} & x_{12} & x_{13} \\\\\n",
        "x_{21} & x_{22} & x_{23} \\\\\n",
        "x_{31} & x_{32} & x_{33} \\\\\n",
        "x_{41} & x_{42} & x_{43} \\\\\n",
        "x_{51} & x_{52} & x_{53} \\\\\n",
        "\\end{bmatrix} $\n",
        "\n",
        "$ \\text{Let } W_{\\text{hidden}} \\text{ be the weight matrix with dimensions 4x4 connecting the input layer to the hidden layer}$:\n",
        "\n",
        "$ W_{\\text{hidden}} =\n",
        "\\begin{bmatrix}\n",
        "w_{11} & w_{12} & w_{13} & \\theta_1 \\\\\n",
        "w_{21} & w_{22} & w_{23} & \\theta_2 \\\\\n",
        "w_{31} & w_{32} & w_{33} & \\theta_3 \\\\\n",
        "w_{41} & w_{42} & w_{43} & \\theta_4 \\\\\n",
        "\\end{bmatrix} $\n",
        "\n",
        "$ \\text{Let } X' \\text{ be the input matrix for the hidden layer, obtained by augmenting ones as an additional column to } X \\text{ as follows}$:\n",
        "\n",
        "$ X' = \\begin{bmatrix}\n",
        "x_{11} & x_{12} & x_{13} & 1 \\\\\n",
        "x_{21} & x_{22} & x_{23} & 1 \\\\\n",
        "x_{31} & x_{32} & x_{33} & 1 \\\\\n",
        "x_{41} & x_{42} & x_{43} & 1 \\\\\n",
        "x_{51} & x_{52} & x_{53} & 1 \\\\\n",
        "\\end{bmatrix} $\n",
        "\n",
        "$ \\text{Let } Z_{\\text{hidden}} \\text{ be the input matrix for the hidden layer, obtained by the matrix multiplication of } W_{\\text{hidden}} \\text{ and } X' \\text{ as follows}$:\n",
        "\n",
        "$ Z_{\\text{hidden}} = X' \\cdot W_{\\text{hidden}} $\n",
        "\n",
        "$$\n",
        "Z_{\\text{hidden}} = \\begin{bmatrix}\n",
        "x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + 1 \\cdot \\theta_1 & x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + 1 \\cdot \\theta_2 & x_{11}w_{13} + x_{12}w_{23} + x_{13}w_{33} + 1 \\cdot \\theta_3 & x_{11} + x_{12} + x_{13} + 1 \\cdot \\theta_4 \\\\\n",
        "x_{21}w_{11} + x_{22}w_{21} + x_{23}w_{31} + 1 \\cdot \\theta_1 & x_{21}w_{12} + x_{22}w_{22} + x_{23}w_{32} + 1 \\cdot \\theta_2 & x_{21}w_{13} + x_{22}w_{23} + x_{23}w_{33} + 1 \\cdot \\theta_3 & x_{21} + x_{22} + x_{23} + 1 \\cdot \\theta_4 \\\\\n",
        "x_{31}w_{11} + x_{32}w_{21} + x_{33}w_{31} + 1 \\cdot \\theta_1 & x_{31}w_{12} + x_{32}w_{22} + x_{33}w_{32} + 1 \\cdot \\theta_2 & x_{31}w_{13} + x_{32}w_{23} + x_{33}w_{33} + 1 \\cdot \\theta_3 & x_{31} + x_{32} + x_{33} + 1 \\cdot \\theta_4 \\\\\n",
        "x_{41}w_{11} + x_{42}w_{21} + x_{43}w_{31} + 1 \\cdot \\theta_1 & x_{41}w_{12} + x_{42}w_{22} + x_{43}w_{32} + 1 \\cdot \\theta_2 & x_{41}w_{13} + x_{42}w_{23} + x_{43}w_{33} + 1 \\cdot \\theta_3 & x_{41} + x_{42} + x_{43} + 1 \\cdot \\theta_4 \\\\\n",
        "x_{51}w_{11} + x_{52}w_{21} + x_{53}w_{31} + 1 \\cdot \\theta_1 & x_{51}w_{12} + x_{52}w_{22} + x_{53}w_{32} + 1 \\cdot \\theta_2 & x_{51}w_{13} + x_{52}w_{23} + x_{53}w_{33} + 1 \\cdot \\theta_3 & x_{51} + x_{52} + x_{53} + 1 \\cdot \\theta_4 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "$ \\text{Let } A_{\\text{hidden}} \\text{ be the activation matrix for the hidden layer, obtained by applying the sigmoid function to each element of } Z_{\\text{hidden}} \\text{ as follows}$:\n",
        "\n",
        "$$\n",
        "A_{\\text{hidden}} = \\begin{bmatrix}\n",
        "\\sigma(x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + 1 \\cdot \\theta_1) & \\sigma(x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + 1 \\cdot \\theta_2) & \\sigma(x_{11}w_{13} + x_{12}w_{23} + x_{13}w_{33} + 1 \\cdot \\theta_3) & \\sigma(x_{11} + x_{12} + x_{13} + 1 \\cdot \\theta_4) \\\\\n",
        "\\sigma(x_{21}w_{11} + x_{22}w_{21} + x_{23}w_{31} + 1 \\cdot \\theta_1) & \\sigma(x_{21}w_{12} + x_{22}w_{22} + x_{23}w_{32} + 1 \\cdot \\theta_2) & \\sigma(x_{21}w_{13} + x_{22}w_{23} + x_{23}w_{33} + 1 \\cdot \\theta_3) & \\sigma(x_{21} + x_{22} + x_{23} + 1 \\cdot \\theta_4) \\\\\n",
        "\\sigma(x_{31}w_{11} + x_{32}w_{21} + x_{33}w_{31} + 1 \\cdot \\theta_1) & \\sigma(x_{31}w_{12} + x_{32}w_{22} + x_{33}w_{32} + 1 \\cdot \\theta_2) & \\sigma(x_{31}w_{13} + x_{32}w_{23} + x_{33}w_{33} + 1 \\cdot \\theta_3) & \\sigma(x_{31} + x_{32} + x_{33} + 1 \\cdot \\theta_4) \\\\\n",
        "\\sigma(x_{41}w_{11} + x_{42}w_{21} + x_{43}w_{31} + 1 \\cdot \\theta_1) & \\sigma(x_{41}w_{12} + x_{42}w_{22} + x_{43}w_{32} + 1 \\cdot \\theta_2) & \\sigma(x_{41}w_{13} + x_{42}w_{23} + x_{43}w_{33} + 1 \\cdot \\theta_3) & \\sigma(x_{41} + x_{42} + x_{43} + 1 \\cdot \\theta_4) \\\\\n",
        "\\sigma(x_{51}w_{11} + x_{52}w_{21} + x_{53}w_{31} + 1 \\cdot \\theta_1) & \\sigma(x_{51}w_{12} + x_{52}w_{22} + x_{53}w_{32} + 1 \\cdot \\theta_2) & \\sigma(x_{51}w_{13} + x_{52}w_{23} + x_{53}w_{33} + 1 \\cdot \\theta_3) & \\sigma(x_{51} + x_{52} + x_{53} + 1 \\cdot \\theta_4) \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$ \\text{Let } w_{\\text{output}} \\text{ be the weight vector for the output layer, connecting the hidden layer to the output layer, given as}: $\n",
        "\n",
        "$$ w_{\\text{output}} = \\begin{bmatrix}\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "w_3 \\\\\n",
        "w_4 \\\\\n",
        "\\end{bmatrix} $$\n",
        "\n",
        "$ \\text{Let } w' \\text{ be the weight vector for the output layer (Single node), obtained by augmenting } \\theta \\text{as an additional column to} w \\text{ as follows}$:\n",
        "\n",
        "$$ w'_{\\text{output}} = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\\\ w_4 \\\\ \\theta_5 \\end{bmatrix} $$\n",
        "\n",
        "The fifth element $theta$ represents the bias associated with the output layer.\n",
        "\n",
        "$ \\text{Let }  z_{\\text{output}} \\text{ be the input vector for the output layer, computed as the dot product of } A_{\\text{hidden}} \\text{ and } w'_{\\text{output}} $:\n",
        "\n",
        "$ z_{\\text{output}} =  A_{\\text{hidden}} \\cdot  w'_{\\text{output}} $\n",
        "\n",
        "$$\n",
        "A_{\\text{out}} = \\begin{bmatrix}\n",
        "\\sigma(x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{11}w_{13} + x_{12}w_{23} + x_{13}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{11} + x_{12} + x_{13} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5 \\\\\n",
        "\\sigma(x_{21}w_{11} + x_{22}w_{21} + x_{23}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{21}w_{12} + x_{22}w_{22} + x_{23}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{21}w_{13} + x_{22}w_{23} + x_{23}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{21} + x_{22} + x_{23} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5 \\\\\n",
        "\\sigma(x_{31}w_{11} + x_{32}w_{21} + x_{33}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{31}w_{12} + x_{32}w_{22} + x_{33}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{31}w_{13} + x_{32}w_{23} + x_{33}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{31} + x_{32} + x_{33} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5 \\\\\n",
        "\\sigma(x_{41}w_{11} + x_{42}w_{21} + x_{43}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{41}w_{12} + x_{42}w_{22} + x_{43}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{41}w_{13} + x_{42}w_{23} + x_{43}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{41} + x_{42} + x_{43} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5 \\\\\n",
        "\\sigma(x_{51}w_{11} + x_{52}w_{21} + x_{53}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{51}w_{12} + x_{52}w_{22} + x_{53}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{51}w_{13} + x_{52}w_{23} + x_{53}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{51} + x_{52} + x_{53} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$ \\text{Let } y \\text{ be the output vector of the output layer, determined by applying the sigmoid function to the input vector of the output layer as follows}: $\n",
        "\n",
        "$ y = \\sigma(z_{\\text{out}}) $\n",
        "\n",
        "$$\n",
        "y = \\begin{bmatrix}\n",
        "\\sigma\\left(\\sigma(x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{11}w_{13} + x_{12}w_{23} + x_{13}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{11} + x_{12} + x_{13} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5\\right) \\\\\n",
        "\\sigma\\left(\\sigma(x_{21}w_{11} + x_{22}w_{21} + x_{23}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{21}w_{12} + x_{22}w_{22} + x_{23}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{21}w_{13} + x_{22}w_{23} + x_{23}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{21} + x_{22} + x_{23} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5\\right) \\\\\n",
        "\\sigma\\left(\\sigma(x_{31}w_{11} + x_{32}w_{21} + x_{33}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{31}w_{12} + x_{32}w_{22} + x_{33}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{31}w_{13} + x_{32}w_{23} + x_{33}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{31} + x_{32} + x_{33} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5\\right) \\\\\n",
        "\\sigma\\left(\\sigma(x_{41}w_{11} + x_{42}w_{21} + x_{43}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{41}w_{12} + x_{42}w_{22} + x_{43}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{41}w_{13} + x_{42}w_{23} + x_{43}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{41} + x_{42} + x_{43} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5\\right) \\\\\n",
        "\\sigma\\left(\\sigma(x_{51}w_{11} + x_{52}w_{21} + x_{53}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{51}w_{12} + x_{52}w_{22} + x_{53}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{51}w_{13} + x_{52}w_{23} + x_{53}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{51} + x_{52} + x_{53} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5\\right)\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "nY12snoRwSDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Input matrix X\n",
        "X = np.array([[1, 2, 3],\n",
        "              [4, 5, 6],\n",
        "              [7, 8, 9],\n",
        "              [10, 11, 12],\n",
        "              [13, 14, 15]])\n",
        "\n",
        "# Weight matrix for the hidden layer\n",
        "W_hidden = np.array([[0.1, 0.2, 0.3, 0.4],\n",
        "                     [0.5, 0.6, 0.7, 0.8],\n",
        "                     [0.9, 1.0, 1.1, 1.2],\n",
        "                     [1.3, 1.4, 1.5, 1.6]])\n",
        "\n",
        "# Adding ones to the input matrix for the hidden layer\n",
        "X_hidden = np.hstack((X, np.ones((X.shape[0], 1))))\n",
        "\n",
        "# Calculating the hidden layer input matrix\n",
        "Z_hidden = np.dot(X_hidden, W_hidden)\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Activation matrix for the hidden layer\n",
        "A_hidden = sigmoid(Z_hidden)\n",
        "\n",
        "# Weight vector for the output layer\n",
        "w_output = np.array([0.1, 0.2, 0.3, 0.4])\n",
        "\n",
        "# Augmenting theta to the weight vector for the output layer\n",
        "w_output_prime = np.append(w_output, 0.5)  # Assuming theta is 0.5\n",
        "\n",
        "# Input vector for the output layer\n",
        "Z_output = np.dot(A_hidden, w_output_prime)\n",
        "\n",
        "# Output vector of the output layer\n",
        "y = sigmoid(Z_output)\n",
        "\n",
        "# Printing the matrices and vectors\n",
        "print(\"X:\")\n",
        "print(X)\n",
        "print(\"\\nW_hidden:\")\n",
        "print(W_hidden)\n",
        "print(\"\\nX_hidden:\")\n",
        "print(X_hidden)\n",
        "print(\"\\nZ_hidden:\")\n",
        "print(Z_hidden)\n",
        "print(\"\\nA_hidden:\")\n",
        "print(A_hidden)\n",
        "print(\"\\nw_output:\")\n",
        "print(w_output)\n",
        "print(\"\\nw_output_prime:\")\n",
        "print(w_output_prime)\n",
        "print(\"\\nZ_output:\")\n",
        "print(Z_output)\n",
        "print(\"\\ny:\")\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "cHmaTjhyHGm1",
        "outputId": "cc431c08-77c6-4377-ccfc-c167d7dad66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ecd89c3052d5>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Input vector for the output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mZ_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_output_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Output vector of the output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (5,4) and (5,) not aligned: 4 (dim 1) != 5 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation in Matrix Form for a Dataset\n",
        "\n",
        "## Error Vector\n",
        "\n",
        "We can define vector $t$, the true observed values for a 5 data-points as:\n",
        "\n",
        "$$ t = \\begin{bmatrix} t_1 \\\\ t_2 \\\\ t_3 \\\\ t_4 \\\\ t_5 \\\\ \\end{bmatrix} $$\n",
        "\n",
        "Now, we can define the scalar $e$, the mean difference between the true values $t$ and predicted values $y$:\n",
        "\n",
        "$$\n",
        "e = \\frac{1}{5}\\sum_{i=1}^{5}(- t_i \\log(y_i) - (1-t_i) \\log(1-y_i))\n",
        "$$\n",
        "\n",
        "Here, \\(t\\) is the true label (0 or 1) and \\(y\\) is the predicted probability of the class being 1. The BCE loss function penalizes the model more as the predicted probability deviates from the actual label.\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "e = \\frac{1}{5} \\cdot \\big[ -t_1 \\cdot \\log(\\sigma\\left(\\sigma(x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{11}w_{13} + x_{12}w_{23} + x_{13}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{11} + x_{12} + x_{13} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5\\right))  \\\\\n",
        "-(1-t_1) \\cdot (1 -\\log(\\sigma\\left(\\sigma(x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{11}w_{13} + x_{12}w_{23} + x_{13}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{11} + x_{12} + x_{13} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5\\right))) \\quad - \\quad ...\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## Gradient of Error Scalar with Respect to Output Layer Weights Vector (Including $\\theta_5$)\n",
        "\n",
        "$$\n",
        "\\frac{\\partial e}{\\partial w'_{\\text{output}}} = \\begin{bmatrix}\n",
        "\\frac{\\partial e}{\\partial w_1} \\\\\n",
        "\\frac{\\partial e}{\\partial w_2} \\\\\n",
        "\\frac{\\partial e}{\\partial w_3} \\\\\n",
        "\\frac{\\partial e}{\\partial w_4} \\\\\n",
        "\\frac{\\partial e}{\\partial \\theta_5} \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "\\frac{\\partial e}{\\partial w_1} = \\frac{1}{5} \\sum_{i=1}^{5} \\frac{\\partial}{\\partial w_1} (- t_i \\log(y_i) - (1-t_i) \\log(1-y_i)) ,\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial e}{\\partial w_2} = \\frac{1}{5} \\sum_{i=1}^{5} \\frac{\\partial}{\\partial w_2} (- t_i \\log(y_i) - (1-t_i) \\log(1-y_i)) ,\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial e}{\\partial w_3} = \\frac{1}{5} \\sum_{i=1}^{5} \\frac{\\partial}{\\partial w_3} (- t_i \\log(y_i) - (1-t_i) \\log(1-y_i)) ,\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial e}{\\partial w_4} = \\frac{1}{5} \\sum_{i=1}^{5} \\frac{\\partial}{\\partial w_4} (- t_i \\log(y_i) - (1-t_i) \\log(1-y_i)) ,\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{and} \\\\\n",
        "\\frac{\\partial e}{\\partial \\theta_5} = \\frac{1}{5} \\sum_{i=1}^{5} \\frac{\\partial}{\\partial \\theta_5} (t_i - y_i) .\n",
        "$$\n",
        "\n",
        "We can expand the expression for $\\frac{\\partial e}{\\partial w_1}$ as follows:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial e}{\\partial w_1} = - \\frac{1}{5} \\times \\big[ \\\\\n",
        "-\\left[\\frac{t_1}{y_1} - \\frac{1-t_1}{1-y_1}\\right] \\cdot\n",
        "\\\\\n",
        "\\bigg[ \\sigma\\left(\\sigma(x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{11}w_{13} + x_{12}w_{23} + x_{13}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{11} + x_{12} + x_{13} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5\\right) \\cdot\\\\\n",
        "\\big(1 - \\big( \\sigma\\left(\\sigma(x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + 1 \\cdot \\theta_1)w_1 + \\sigma(x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + 1 \\cdot \\theta_2)w_2 + \\sigma(x_{11}w_{13} + x_{12}w_{23} + x_{13}w_{33} + 1 \\cdot \\theta_3)w_3 + \\sigma(x_{11} + x_{12} + x_{13} + 1 \\cdot \\theta_4)w_4 + 1 \\cdot \\theta_5\\right) \\big) \\bigg] \\cdot \\\\\n",
        "\\bigg[ \\sigma(x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + 1 \\cdot \\theta_1) \\bigg]\n",
        "\\\\\n",
        "+ \\quad ...\n",
        "$$\n",
        "\n",
        "We can use a similar approach to find the expressions for $\\frac{\\partial e}{\\partial w_2}, \\frac{\\partial e}{\\partial w_3}, \\frac{\\partial e}{\\partial w_4},$ and $\\frac{\\partial e}{\\partial \\theta_5}$ by differentiating with respect to $w_2, w_3, w_4,$ and $\\theta_5$ respectively.\n",
        "\n",
        "The above gradient vector can be calculated easily by expressing it as:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial e}{\\partial w'} = \\frac{\\partial e}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times \\frac{\\partial z_{\\text{out}}}{\\partial w'}  =  -\\left[\\frac{t}{y} - \\frac{1-t}{1-y}\\right] \\times \\sigma(z_{\\text{out}}) \\times \\sigma(1 -  z_{\\text{out}}) \\cdot a_{\\text{hidden}}\n",
        "$$\n",
        "\n",
        "We can express the gradient vector $\\frac{\\partial E}{\\partial W'_{\\text{hidden}}}$ as follows:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial e}{\\partial W'_{\\text{hidden}}} = \\frac{\\partial e}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times \\frac{\\partial z_{\\text{out}}}{\\partial a_{i, \\text{hidden}}} \\times \\frac{\\partial a_{i, \\text{hidden}}}{\\partial z_{i, \\text{hidden}}} \\times \\frac{\\partial z_{i, \\text{hidden}}}{\\partial w_{ij}} \\\\\n",
        "= = \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z_{\\text{out}}} \\times w_{\\text{output}} \\odot \\sigma(z_{\\text{hidden}}) \\otimes x'_{\\text{input}}\n",
        "$$\n",
        "\n",
        "## Update Weights (including $\\theta$)\n",
        "\n",
        "$$\n",
        "w'_{\\text{output}}(n+1) = w'_{\\text{output}}(n) - \\alpha \\cdot \\frac{\\partial E}{\\partial w'_{\\text{output}}}\n",
        "$$\n",
        "\n",
        "where $w'_{\\text{output}}(n+1)$ is the updated weight vector, $w'_{\\text{output}}(n)$ is the current weight vector, $\\alpha$ is the learning rate, and $\\frac{\\partial E}{\\partial w'_{\\text{output}}}$ is the gradient vector for the output layer weights.\n",
        "\n",
        "$$\n",
        "W'_{\\text{hidden}}(n+1) = W'_{\\text{hidden}}(n) - \\alpha \\cdot \\frac{\\partial E}{\\partial W'_{\\text{hidden}}}\n",
        "$$\n",
        "\n",
        "where $W'_{\\text{hidden}}(n+1)$ is the updated weight matrix, $W'_{\\text{hidden}}(n)$ is the current weight matrix, $\\alpha $ is the learning rate, and $\\frac{\\partial E}{\\partial W'_{\\text{hidden}}}$ is the gradient matrix for the hidden layer weights."
      ],
      "metadata": {
        "id": "aBdfMKpYICNH"
      }
    }
  ]
}